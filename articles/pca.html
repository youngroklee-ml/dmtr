<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>주성분분석 • dmtr</title>
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/css/bootstrap.min.css" integrity="sha256-bZLfwXAP04zRMK2BjiO8iu9pf4FbLqX6zitd+tIvLhE=" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="주성분분석">
<meta property="og:description" content="dmtr">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body data-spy="scroll" data-target="#toc">
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">dmtr</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">0.0.0.9000</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">
    <span class="fas fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/discriminant-analysis.html">판별분석</a>
    </li>
    <li>
      <a href="../articles/logistic-regression.html">로지스틱 회귀분석</a>
    </li>
    <li>
      <a href="../articles/pca.html">주성분분석</a>
    </li>
    <li>
      <a href="../articles/plsr.html">부분최소자승 회귀분석</a>
    </li>
    <li>
      <a href="../articles/regression.html">회귀분석</a>
    </li>
    <li>
      <a href="../articles/tree.html">트리기반 기법</a>
    </li>
  </ul>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right"></ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><script src="pca_files/header-attrs-2.9/header-attrs.js"></script><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>주성분분석</h1>
            
      
      
      <div class="hidden name"><code>pca.Rmd</code></div>

    </div>

    
    
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">dmtr</span><span class="op">)</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://dplyr.tidyverse.org">dplyr</a></span><span class="op">)</span></code></pre></div>
<div id="pca-data" class="section level1" number="1">
<h1 class="hasAnchor">
<a href="#pca-data" class="anchor"></a><span class="header-section-number">1</span> 데이터</h1>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">biometric</span>, package <span class="op">=</span> <span class="st">"dmtr"</span><span class="op">)</span></code></pre></div>
<table class="table">
<caption>
<span id="tab:biometric-data-print">Table 1.1: </span>나이, 키, 몸무게 데이터</caption>
<thead><tr class="header">
<th align="right">age</th>
<th align="right">height</th>
<th align="right">weight</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="right">21</td>
<td align="right">170</td>
<td align="right">60</td>
</tr>
<tr class="even">
<td align="right">47</td>
<td align="right">167</td>
<td align="right">65</td>
</tr>
<tr class="odd">
<td align="right">36</td>
<td align="right">173</td>
<td align="right">67</td>
</tr>
<tr class="even">
<td align="right">15</td>
<td align="right">165</td>
<td align="right">54</td>
</tr>
<tr class="odd">
<td align="right">54</td>
<td align="right">168</td>
<td align="right">73</td>
</tr>
<tr class="even">
<td align="right">25</td>
<td align="right">177</td>
<td align="right">71</td>
</tr>
<tr class="odd">
<td align="right">32</td>
<td align="right">169</td>
<td align="right">68</td>
</tr>
<tr class="even">
<td align="right">18</td>
<td align="right">172</td>
<td align="right">62</td>
</tr>
<tr class="odd">
<td align="right">43</td>
<td align="right">171</td>
<td align="right">66</td>
</tr>
<tr class="even">
<td align="right">28</td>
<td align="right">175</td>
<td align="right">68</td>
</tr>
</tbody>
</table>
</div>
<div id="pca-ss" class="section level1" number="2">
<h1 class="hasAnchor">
<a href="#pca-ss" class="anchor"></a><span class="header-section-number">2</span> 변수의 변동과 제곱합</h1>
<p>총 <span class="math inline">\(k\)</span>개의 독립변수가 있고 각 독립변수에 대하여 <span class="math inline">\(n\)</span>개의 관측치가 있다고 하자. 이 때, <span class="math inline">\(x_{ij}\)</span>를 <span class="math inline">\(j\)</span>번째 독립변수에 대한 <span class="math inline">\(i\)</span>번째 관측치라 하자. 즉, 관측데이터는 아래와 같은 행렬로 표현할 수 있다.</p>
<p><span class="math display">\[\begin{equation*}
\mathbf{X} = \left[ \begin{array}{c c c c}
x_{11} &amp; x_{12} &amp; \cdots &amp; x_{1k}\\
x_{21} &amp; x_{22} &amp; \cdots &amp; x_{2k}\\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
x_{n1} &amp; x_{n2} &amp; \cdots &amp; x_{nk}
\end{array} \right]
\end{equation*}\]</span></p>
<p>주성분분석에서는 통상 원데이터를 그대로 사용하지 않고 적절한 변환을 취하는데, 주로 평균조정(mean-centered) 데이터를 이용한다. 이는 아래와 같이 독립변수에 대하여 표본평균을 뺌으로써 조정된 변수의 평균이 0이 되도록 하는 것이다.</p>
<p><span class="math display" id="eq:pca-mean-centering">\[\begin{equation}
\tilde{x}_{ij} \leftarrow x_{ij} - \frac{1}{n} \sum_{l = 1}^{n} x_{lj} \tag{2.1}
\end{equation}\]</span></p>
<p>이후에 별도의 언급이 없는 한, 행렬 <span class="math inline">\(\mathbf{X}\)</span> 및 변수값 <span class="math inline">\(x_{ij}\)</span>는 식 <a href="#eq:pca-mean-centering">(2.1)</a>을 이용하여 평균조정된 것으로 가정한다.</p>
<p>이 밖에도 다른 변환이 사용되는 경우가 있는데, 특히 단위 등이 서로 상이할 경우에는 평균조정 이후 추가로 각 변수의 분산이 1이 되도록 분산조정을 한다.</p>
<p><span class="math display" id="eq:pca-scaling">\[\begin{equation*}
z_{ij} \leftarrow \frac{x_{ij}}{\sqrt{\frac{1}{n - 1} \sum_{l =1}^{n} x_{lj}^2}} \tag{2.2}
\end{equation*}\]</span></p>
<p>이 때, 식 <a href="#eq:pca-scaling">(2.2)</a>에서 분모 부분은 변수의 표본 표준편차로 <span class="math inline">\(s_j\)</span>로 표현된다.</p>
<p><span class="math display">\[\begin{equation*}
s_{j} = \sqrt{\frac{1}{n - 1} \sum_{l =1}^{n} x_{lj}^2}
\end{equation*}\]</span></p>
<p>이후 분산조정을 이용하는 경우 행렬 <span class="math inline">\(\mathbf{Z}\)</span> 및 변수값 <span class="math inline">\(z_{ij}\)</span>로 표현한다.</p>
<p><span class="math display">\[\begin{equation*}
\mathbf{Z} = \left[ \begin{array}{c c c c}
z_{11} &amp; z_{12} &amp; \cdots &amp; z_{1k}\\
z_{21} &amp; z_{22} &amp; \cdots &amp; z_{2k}\\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
z_{n1} &amp; z_{n2} &amp; \cdots &amp; z_{nk}
\end{array} \right]
\end{equation*}\]</span></p>
<p>변수벡터 <span class="math inline">\(\mathbf{x}_j = [x_{1j} \, x_{2j} \, \cdots \, x_{nj}]^\top\)</span>에 대한 제곱합의 정의는 아래와 같다.</p>
<p><span class="math display">\[\begin{equation}
SS(\mathbf{x}_j) = \mathbf{x}_j^\top \mathbf{x}_j = \sum_{i = 1}^{n} x_{ij}^2
\end{equation}\]</span></p>
</div>
<div id="pca-nipals" class="section level1" number="3">
<h1 class="hasAnchor">
<a href="#pca-nipals" class="anchor"></a><span class="header-section-number">3</span> NIPALS 알고리즘</h1>
<p>NIPALS(Nonlinear Iterative Paritial Least Squares) 알고리즘은 반복적(iterative) 알고리즘을 이용하여 변동 기여율이 가장 큰 주성분부터 가장 작은 주성분까지 순차적으로 고유벡터와 주성분 스코어를 구하는 방법이다.</p>
<p>우선, 특이치 분해에서 사용한 식을 단순화하여, 분산조정된 행렬 <span class="math inline">\(\mathbf{Z}\)</span>가 아래와 같이 주성분 스코어 행렬 <span class="math inline">\(\mathbf{T}\)</span>와 고유벡터 행렬 <span class="math inline">\(\mathbf{V}\)</span>로 분해된다고 하자. (분산조정 대신 평균조정만을 원할 경우 <span class="math inline">\(\mathbf{Z}\)</span> 대신 <span class="math inline">\(\mathbf{X}\)</span>를 사용)</p>
<p><span class="math display">\[ \mathbf{Z} = \mathbf{U} \mathbf{D} \mathbf{V}^\top = \mathbf{T} \mathbf{V}^\top \]</span></p>
<p>즉, 주성분 스코어 행렬 <span class="math inline">\(\mathbf{T}\)</span>는 아래와 같다.</p>
<p><span class="math display">\[ \mathbf{T} = \mathbf{Z} \mathbf{V} \]</span></p>
<p>NIPALS 알고리즘은 아래와 같이 주성분 스코어 행렬 <span class="math inline">\(\mathbf{T}\)</span>의 열과 고유벡터행렬 <span class="math inline">\(\mathbf{V}\)</span>의 열을 동시에 구한다.</p>
<ul>
<li>
<strong>[단계 0]</strong> 반복알고리즘 수행을 위한 초기화를 한다. <span class="math inline">\(h \leftarrow 1\)</span>, <span class="math inline">\(\mathbf{Z}_h \leftarrow \mathbf{Z}\)</span>.</li>
<li>
<strong>[단계 1]</strong> 데이터 행렬 <span class="math inline">\(\mathbf{Z}_h\)</span>의 임의의 열 하나를 주성분 스코어 벡터 <span class="math inline">\(\mathbf{t}_h\)</span>로 선정한다.</li>
<li>
<strong>[단계 2]</strong> 로딩벡터를 구한다. <span class="math inline">\(\mathbf{v}_h \leftarrow \mathbf{Z}_h \mathbf{t}_h \left/ \sqrt{\mathbf{t}_h^\top \mathbf{t}_h} \right.\)</span>
</li>
<li>
<strong>[단계 3]</strong> 로딩벡터의 크기가 1이 되도록 한다. <span class="math inline">\(\mathbf{v}_h \leftarrow \mathbf{v}_h \left/ \sqrt{\mathbf{v}_h^\top \mathbf{v}_h} \right.\)</span>
</li>
<li>
<strong>[단계 4]</strong> 주성분 스코어 벡터를 로딩벡터에 기반하여 계산한다. <span class="math inline">\(\mathbf{t}_h \leftarrow \mathbf{Z}_h \mathbf{v}_h\)</span>
</li>
<li>
<strong>[단계 5]</strong> 주성분 스코어 벡터 <span class="math inline">\(\mathbf{t}_h\)</span>가 수렴하였으면 [단계 6]으로 진행하고, 그렇지 않으면 [단계 2]로 돌아간다.</li>
<li>
<strong>[단계 6]</strong> 데이터 행렬 <span class="math inline">\(\mathbf{Z}_h\)</span>로부터 새로 얻어진 주성분 벡터 <span class="math inline">\(\mathbf{t}_h\)</span>와 고유벡터 <span class="math inline">\(\mathbf{v}_h\)</span>가 설명하는 부분을 제거하고 나머지 변동만을 담은 새로운 데이터 행렬 <span class="math inline">\(\mathbf{Z}_{h + 1}\)</span>을 구한다.
<span class="math display">\[ \mathbf{Z}_{h + 1} \leftarrow \mathbf{Z}_{h} - \mathbf{t}_h \mathbf{v}_h^\top \]</span>
</li>
<li>
<strong>[단계 7]</strong> <span class="math inline">\(h \leftarrow h + 1\)</span>로 업데이트하고, [단계 1]로 돌아간다. [단계 1] - [단계 7]의 과정을 <span class="math inline">\(\mathbf{Z}\)</span>의 rank 수만큼의 주성분을 얻을 때까지 반복한다.</li>
</ul>
<p>위 반복 알고리즘을 수행하는 함수를 아래와 같이 구성해보자. 아래 함수에서 입력변수 <code>X</code>는 데이터 행렬으로, 평균조정된 행렬 <span class="math inline">\(\mathbf{X}\)</span>나 분산조정된 <span class="math inline">\(\mathbf{Z}\)</span> 모두 사용 가능하다. 입력변수 <code>.pc</code>은 추출하고자 하는 주성분의 개수이다.</p>
<pre><code>function (X, .pc = NULL) 
{
    if (rlang::is_empty(.pc) || (.pc &gt; min(dim(X)))) {
        .pc &lt;- min(dim(X))
    }
    Th &lt;- matrix(NA, nrow = nrow(X), ncol = .pc)
    Vh &lt;- matrix(NA, nrow = ncol(X), ncol = .pc)
    for (h in seq_len(.pc)) {
        j &lt;- sample(ncol(X), 1L)
        Th[, h] &lt;- X[, j]
        while (TRUE) {
            Vh[, h] &lt;- t(t(Th[, h]) %*% X/(norm(Th[, h], "2")^2))
            Vh[, h] &lt;- Vh[, h]/norm(Vh[, h], "2")
            th &lt;- X %*% Vh[, h]
            if (all(dplyr::near(Th[, h], th))) 
                break
            Th[, h] &lt;- th
        }
        X &lt;- X - Th[, h] %*% t(Vh[, h])
    }
    return(list(T = Th, V = Vh))
}
&lt;bytecode: 0x7ff190a65318&gt;
&lt;environment: namespace:dmtr&gt;</code></pre>
<p>위 함수를 이용하여 주성분 분해를 수행하는 함수 <code><a href="../reference/fit_pca.html">fit_pca()</a></code>를 실행해보자.</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="../reference/fit_pca.html">fit_pca</a></span><span class="op">(</span><span class="va">biometric</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">age</span>, <span class="va">height</span>, <span class="va">weight</span><span class="op">)</span>, .pc <span class="op">=</span> <span class="fl">2L</span><span class="op">)</span>
<span class="co">#&gt; $eig</span>
<span class="co">#&gt; [1] 3.961213 3.247934</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $score</span>
<span class="co">#&gt;              PC1        PC2</span>
<span class="co">#&gt;  [1,] -1.2672472  0.2796131</span>
<span class="co">#&gt;  [2,]  0.2485837 -1.4996459</span>
<span class="co">#&gt;  [3,]  0.6166785  0.3344830</span>
<span class="co">#&gt;  [4,] -2.8174942 -0.6097016</span>
<span class="co">#&gt;  [5,]  1.7218380 -1.5057495</span>
<span class="co">#&gt;  [6,]  1.0580977  1.7554053</span>
<span class="co">#&gt;  [7,]  0.1870461 -0.3451973</span>
<span class="co">#&gt;  [8,] -0.9370744  0.8763285</span>
<span class="co">#&gt;  [9,]  0.5953602 -0.4324721</span>
<span class="co">#&gt; [10,]  0.5942116  1.1469365</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $loadings</span>
<span class="co">#&gt;              PC1         PC2</span>
<span class="co">#&gt; age    0.5684412 -0.59068028</span>
<span class="co">#&gt; height 0.3574679  0.80427250</span>
<span class="co">#&gt; weight 0.7410069  0.06513488</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $ncomp</span>
<span class="co">#&gt; [1] 2</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $R2</span>
<span class="co">#&gt; [1] 0.5811558 0.3907064</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $center</span>
<span class="co">#&gt;    age height weight </span>
<span class="co">#&gt;   31.9  170.7   65.4 </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $scale</span>
<span class="co">#&gt;       age    height    weight </span>
<span class="co">#&gt; 12.982467  3.683296  5.541761</span></code></pre></div>
</div>
<div id="pcr" class="section level1" number="4">
<h1 class="hasAnchor">
<a href="#pcr" class="anchor"></a><span class="header-section-number">4</span> 주성분 회귀분석</h1>
<p>본 절에서 독립변수 행렬 <span class="math inline">\(\mathbf{X}\)</span>을 평균조정 이전의 원래 독립변수 행렬이라고 하자. 종속변수 관측치 벡터 <span class="math inline">\(\mathbf{y}\)</span>를 독립변수 데이터 행렬 <span class="math inline">\(\mathbf{X}\)</span>로 설명하는 회귀 모형을 추정하고자 할 때, 독립변수 행렬 <span class="math inline">\(\mathbf{X}\)</span>의 열벡터 간 다중공선성(multicollinearity)이 높으면 최소자승법에 의한 <span class="math inline">\(\boldsymbol{\beta}\)</span>의 추정치의 분산이 커지는 문제가 있으며, <span class="math inline">\(\mathbf{X}\)</span> 행렬의 관측수보다 변수 수가 많을 때는 <span class="math inline">\(\boldsymbol{\beta}\)</span> 추정치를 구할 수 없다. 이 문제를 해결하기 위해 주성분 회귀분석(principal component regression; PCR)에서는 <span class="math inline">\(\mathbf{X}\)</span> 변동 대부분을 설명하는 <span class="math inline">\(A\)</span>개 (<span class="math inline">\(A \leq rank(\mathbf{X})\)</span>)의 주성분 스코어를 독립변수로 사용한다.</p>
<div id="모형-추정" class="section level2" number="4.1">
<h2 class="hasAnchor">
<a href="#%EB%AA%A8%ED%98%95-%EC%B6%94%EC%A0%95" class="anchor"></a><span class="header-section-number">4.1</span> 모형 추정</h2>
<p>위 NIPALS 알고리즘을 통해 얻어진 첫 <span class="math inline">\(A\)</span>개의 주성분으로 이루어진 주성분 스코어 행렬을 <span class="math inline">\(\mathbf{T}_A\)</span>라 하자.</p>
<p><span class="math display">\[ \mathbf{T}_A = \left[ \mathbf{t}_1 \, \mathbf{t}_2 \, \cdots \, \mathbf{t}_A  \right] \]</span></p>
<p><span class="math display" id="eq:pcr-model">\[\begin{equation}
\mathbf{y} = q_0 + q_1 \mathbf{t}_1 + q_2 \mathbf{t}_2 + \cdots + q_A \mathbf{t}_A + \mathbf{f} \tag{4.1}
\end{equation}\]</span></p>
<p>여기서 <span class="math inline">\(\mathbf{f}\)</span>는 오차항을 나타내는 벡터이며, <span class="math inline">\(q_0\)</span>는 intercept, <span class="math inline">\(q_1, \cdots, q_A\)</span>는 각 주성분 스코어에 해당하는 회귀계수들이다. 위 모형은 다중회귀모형으로 볼 수 있으므로, 다중회귀모형에 대한 모든 이론이 적용될 수 있다. 또한 위 모형에서 각 주성분 스코어 벡터 <span class="math inline">\(\mathbf{t}_1, \ldots, \mathbf{t}_A\)</span>는 서로 선형 독립적(linearly independent)이므로, 회귀성 검정이 용이한 측면이 있다.</p>
<p>위 예제 데이터에서 <code>weight</code>를 종속변수로 하고 <code>age</code>와 <code>height</code>를 독립변수로 사용하여 주성분 회귀분석을 수행해보자. 이 때, 두 개의 주성분을 모두 회귀모형의 독립변수로 사용해보자.</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">y</span> <span class="op">&lt;-</span> <span class="va">biometric</span> <span class="op">%&gt;%</span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="va">weight</span><span class="op">)</span>
<span class="va">pc_fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/fit_pca.html">fit_pca</a></span><span class="op">(</span><span class="va">biometric</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">age</span>, <span class="va">height</span><span class="op">)</span>, .pc <span class="op">=</span> <span class="fl">2L</span><span class="op">)</span>
<span class="va">T_A</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://tibble.tidyverse.org/reference/as_tibble.html">as_tibble</a></span><span class="op">(</span><span class="va">pc_fit</span><span class="op">[[</span><span class="st">"score"</span><span class="op">]</span><span class="op">]</span><span class="op">)</span>
<span class="va">reg_data</span> <span class="op">&lt;-</span> <span class="va">y</span> <span class="op">%&gt;%</span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/bind.html">bind_cols</a></span><span class="op">(</span><span class="va">T_A</span><span class="op">)</span>
<span class="va">lm_fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/fit_linear_regression.html">fit_linear_regression</a></span><span class="op">(</span><span class="va">reg_data</span>, <span class="va">weight</span>, <span class="fu"><a href="https://tidyselect.r-lib.org/reference/all_of.html">all_of</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/names.html">names</a></span><span class="op">(</span><span class="va">T_A</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>
<span class="va">lm_fit</span>
<span class="co">#&gt; $betas</span>
<span class="co">#&gt; (Intercept)         PC1         PC2 </span>
<span class="co">#&gt;  65.3999999  -0.5332898   5.5093680 </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $hessian</span>
<span class="co">#&gt;               (Intercept)          PC1           PC2</span>
<span class="co">#&gt; (Intercept)  2.000000e+01 6.994405e-12 -3.649858e-12</span>
<span class="co">#&gt; PC1          6.994405e-12 2.123307e+01  5.065393e-12</span>
<span class="co">#&gt; PC2         -3.649858e-12 5.065393e-12  1.476693e+01</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $mse</span>
<span class="co">#&gt; [1] 7.038464</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $df</span>
<span class="co">#&gt; [1] 7</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $se</span>
<span class="co">#&gt; (Intercept)         PC1         PC2 </span>
<span class="co">#&gt;   0.8389556   0.8142308   0.9763576 </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $sst</span>
<span class="co">#&gt; [1] 276.4</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $rsq</span>
<span class="co">#&gt; [1] 0.8217466</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $rsqadj</span>
<span class="co">#&gt; [1] 0.770817</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $n</span>
<span class="co">#&gt; [1] 10</span></code></pre></div>
<p>위 과정을 함수 <code><a href="../reference/fit_pcr.html">fit_pcr()</a></code>로 수행할 수 있다. 함수 <code><a href="../reference/fit_pcr.html">fit_pcr()</a></code>의 결과값은 주성분 분석 함수 <code><a href="../reference/fit_pca.html">fit_pca()</a></code>의 결과와 회귀분석 함수 <code><a href="../reference/fit_linear_regression.html">fit_linear_regression()</a></code>의 결과를 동시에 포함한다.</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/fit_pcr.html">fit_pcr</a></span><span class="op">(</span><span class="va">biometric</span>, <span class="va">weight</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">age</span>, <span class="va">height</span><span class="op">)</span>, .pc <span class="op">=</span> <span class="fl">2L</span><span class="op">)</span></code></pre></div>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="../reference/ttest_linear_regression.html">ttest_linear_regression</a></span><span class="op">(</span><span class="va">fit</span><span class="op">)</span>
<span class="co">#&gt; # A tibble: 3 x 5</span>
<span class="co">#&gt;   term        estimate std_error t_statistic  p_value</span>
<span class="co">#&gt;   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;    &lt;dbl&gt;</span>
<span class="co">#&gt; 1 (Intercept)   65.4       0.839      78.0   1.50e-11</span>
<span class="co">#&gt; 2 PC1           -0.533     0.814      -0.655 5.33e- 1</span>
<span class="co">#&gt; 3 PC2            5.51      0.976       5.64  7.80e- 4</span></code></pre></div>
<p>위 두 개의 주성분을 모두 이용한 회귀모형의 경우, 원래 독립변수 <code>age</code>와 <code>height</code>를 그대로 이용하여 추정한 회귀모형과 정확히 일치하는 종속변수에 대한 설명력을 지닌다. 다만, 위 주성분 회귀분석 모형의 경우 주성분 스코어가 직교하므로 회귀계수벡터 추정량의 분산-공분산행렬에서 공분산이 0임을 볼 수 있다.</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">fit</span><span class="op">$</span><span class="va">mse</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/solve.html">solve</a></span><span class="op">(</span><span class="va">fit</span><span class="op">$</span><span class="va">hessian</span> <span class="op">/</span> <span class="fl">2</span><span class="op">)</span>
<span class="co">#&gt;               (Intercept)           PC1           PC2</span>
<span class="co">#&gt; (Intercept)  7.038464e-01 -2.318547e-13  1.739658e-13</span>
<span class="co">#&gt; PC1         -2.318547e-13  6.629718e-01 -2.274144e-13</span>
<span class="co">#&gt; PC2          1.739658e-13 -2.274144e-13  9.532742e-01</span></code></pre></div>
<p>위 주성분 회귀분석에 단계별 선택방법을 적용할 경우, 두 번째 주성분 스코어만을 독립변수로 사용한 회귀모형이 최종적으로 선택되며, 이 때의 수정결정계수가 두 개의 주성분을 모두 이용한 모형보다 높음을 확인할 수 있다.</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">selected_pc</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/select_variables_stepwise.html">select_variables_stepwise</a></span><span class="op">(</span><span class="va">reg_data</span>, <span class="va">weight</span>, <span class="fu"><a href="https://rdrr.io/r/base/names.html">names</a></span><span class="op">(</span><span class="va">T_A</span><span class="op">)</span><span class="op">)</span>
<span class="co">#&gt; Inital variable:  PC2 , p-value =  0.0003803436  &lt;  0.05 </span>
<span class="co">#&gt; Iteration  1 : forward selection - no additional variable gives statistically significant improvement of the fit.</span>
<span class="fu"><a href="../reference/fit_linear_regression.html">fit_linear_regression</a></span><span class="op">(</span><span class="va">reg_data</span>, <span class="va">weight</span>, <span class="fu"><a href="https://tidyselect.r-lib.org/reference/all_of.html">all_of</a></span><span class="op">(</span><span class="va">selected_pc</span><span class="op">)</span><span class="op">)</span>
<span class="co">#&gt; $betas</span>
<span class="co">#&gt; (Intercept)         PC2 </span>
<span class="co">#&gt;   65.399987    5.509376 </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $hessian</span>
<span class="co">#&gt;              (Intercept)          PC2</span>
<span class="co">#&gt; (Intercept) 2.000000e+01 1.099121e-11</span>
<span class="co">#&gt; PC2         1.099121e-11 1.476693e+01</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $mse</span>
<span class="co">#&gt; [1] 6.536071</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $df</span>
<span class="co">#&gt; [1] 8</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $se</span>
<span class="co">#&gt; (Intercept)         PC2 </span>
<span class="co">#&gt;   0.8084597   0.9408672 </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $sst</span>
<span class="co">#&gt; [1] 276.4</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $rsq</span>
<span class="co">#&gt; [1] 0.8108228</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $rsqadj</span>
<span class="co">#&gt; [1] 0.7871757</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $n</span>
<span class="co">#&gt; [1] 10</span></code></pre></div>
<p>반면, 첫 번째 주성분 스코어만을 이용한 모형의 경우, 종속변수를 거의 설명하지 못하며, 수정결정계수는 0보다도 작음을 아래에서 확인할 수 있다. 이는 독립변수의 분산을 더 많이 설명하는 잠재변수가 반드시 종속변수의 분산 또한 더 많이 설명하지는 않는다는 것을 보여준다.</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="../reference/fit_linear_regression.html">fit_linear_regression</a></span><span class="op">(</span><span class="va">reg_data</span>, <span class="va">weight</span>, <span class="va">PC1</span><span class="op">)</span>
<span class="co">#&gt; $betas</span>
<span class="co">#&gt; (Intercept)         PC1 </span>
<span class="co">#&gt;  65.4000002  -0.5332894 </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $hessian</span>
<span class="co">#&gt;               (Intercept)           PC1</span>
<span class="co">#&gt; (Intercept)  2.000000e+01 -7.771561e-12</span>
<span class="co">#&gt; PC1         -7.771561e-12  2.123307e+01</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $mse</span>
<span class="co">#&gt; [1] 34.17259</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $df</span>
<span class="co">#&gt; [1] 8</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $se</span>
<span class="co">#&gt; (Intercept)         PC1 </span>
<span class="co">#&gt;    1.848583    1.794103 </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $sst</span>
<span class="co">#&gt; [1] 276.4</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $rsq</span>
<span class="co">#&gt; [1] 0.01092373</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $rsqadj</span>
<span class="co">#&gt; [1] -0.1127108</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $n</span>
<span class="co">#&gt; [1] 10</span></code></pre></div>
<p>회귀모형에 적합한 잠재변수를 추출하는 방법으로 부분최소자승 회귀분석이 있으며, 이는 별도의 문서에서 설명하도록 한다.</p>
</div>
<div id="회귀계수-변환" class="section level2" number="4.2">
<h2 class="hasAnchor">
<a href="#%ED%9A%8C%EA%B7%80%EA%B3%84%EC%88%98-%EB%B3%80%ED%99%98" class="anchor"></a><span class="header-section-number">4.2</span> 회귀계수 변환</h2>
<p>원래 변수를 독립변수로 대한 회귀계수를 주성분 회귀모형으로부터 계산할 수 있다. 이는 원래 변수와 종속변수 간의 관계를 살펴보는 데 유용하다.</p>
<p>주성분 분해 시 각 변수에 적용된 평균 조정값을 <span class="math inline">\(m_j\)</span>, 분산 조정값을 <span class="math inline">\(s_j\)</span>라 할 때, 추정된 주성분 회귀모형은 아래와 같이 원래 변수를 독립변수로 하는 회귀모형으로 선형변환할 수 있다. 여기서 <span class="math inline">\(v_{ja}\)</span>는 <span class="math inline">\(a\)</span>번째 주성분에 대한 <span class="math inline">\(j\)</span>번째 변수의 가중치를 나타낸다.</p>
<p><span class="math display">\[\begin{eqnarray*}
\hat{y}_i &amp;=&amp; \hat{q}_0 + \sum_{a = 1}^{A} \hat{q}_a t_{ia}\\
&amp;=&amp; \hat{q}_0 + \sum_{a = 1}^{A} \hat{q}_a \sum_{j = 1}^{k} v_{ja} \frac{x_{ij} - m_j}{s_j}\\
&amp;=&amp; \hat{q}_0 - \sum_{a = 1}^{A} \hat{q}_a \sum_{j = 1}^{k} v_{ja} \frac{m_j}{s_j} + \sum_{a = 1}^{A} \sum_{j = 1}^{k} \hat{q}_a \frac{v_{ja}}{s_j} x_{ij}\\
&amp;=&amp; \hat{q}_0 - \sum_{a = 1}^{A} \sum_{j = 1}^{k} \hat{q}_a v_{ja} \frac{m_j}{s_j} + \sum_{j = 1}^{k} \sum_{a = 1}^{A} \hat{q}_a \frac{v_{ja}}{s_j} x_{ij}\\
&amp;=&amp; \hat{\beta}_0 + \sum_{j = 1}^{k} \hat{\beta}_j x_{ij}
\end{eqnarray*}\]</span></p>
<p>여기에서, 아래와 같은 관계식이 성립한다.</p>
<p><span class="math display">\[
\hat{\beta}_0 = \hat{q}_0 - \sum_{a = 1}^{A} \sum_{j = 1}^{k} \hat{q}_a v_{ja} \frac{m_j}{s_j}
\]</span></p>
<p><span class="math display">\[
\hat{\beta}_j = \sum_{a = 1}^{A} \hat{q}_a \frac{v_{ja}}{s_j}
\]</span></p>
<p>위에서 수행한 함수 <code><a href="../reference/fit_pcr.html">fit_pcr()</a></code>의 결과값 <code>fit</code>은 주성분 분해 시 적용된 평균조정과 분산조정값 및 가중치 <span class="math inline">\(v_{ja}\)</span>를 아래와 같이 <code>center</code>, <code>scale</code>, <code>loadings</code>원소에 각각 저장하고 있다.</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">fit</span><span class="op">$</span><span class="va">center</span>
<span class="co">#&gt;    age height </span>
<span class="co">#&gt;   31.9  170.7</span>
<span class="va">fit</span><span class="op">$</span><span class="va">scale</span>
<span class="co">#&gt;       age    height </span>
<span class="co">#&gt; 12.982467  3.683296</span>
<span class="va">fit</span><span class="op">$</span><span class="va">loadings</span>
<span class="co">#&gt;               PC1       PC2</span>
<span class="co">#&gt; age    -0.7071068 0.7071068</span>
<span class="co">#&gt; height  0.7071068 0.7071068</span></code></pre></div>
<p>따라서, 위 원소값들과 추정된 주성분 회귀계수 <code>betas</code>를 사용하여 아래와 같이 원래 변수를 독립변수로 하는 회귀모형의 회귀계수 추정값을 계산할 수 있다.</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">intercept</span> <span class="op">&lt;-</span> <span class="va">fit</span><span class="op">$</span><span class="va">betas</span><span class="op">[</span><span class="st">"(Intercept)"</span><span class="op">]</span> <span class="op">-</span>
  <span class="fu"><a href="https://rdrr.io/r/base/drop.html">drop</a></span><span class="op">(</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/t.html">t</a></span><span class="op">(</span><span class="va">fit</span><span class="op">$</span><span class="va">center</span> <span class="op">/</span> <span class="va">fit</span><span class="op">$</span><span class="va">scale</span><span class="op">)</span> <span class="op">%*%</span> <span class="va">fit</span><span class="op">$</span><span class="va">loadings</span><span class="op">)</span> <span class="op">%*%</span>
     <span class="va">fit</span><span class="op">$</span><span class="va">betas</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/colnames.html">colnames</a></span><span class="op">(</span><span class="va">fit</span><span class="op">$</span><span class="va">loadings</span><span class="op">)</span><span class="op">]</span><span class="op">)</span>
<span class="va">intercept</span>
<span class="co">#&gt; (Intercept) </span>
<span class="co">#&gt;   -108.1671</span></code></pre></div>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">betas</span> <span class="op">&lt;-</span> <span class="op">(</span><span class="fl">1</span> <span class="op">/</span> <span class="va">fit</span><span class="op">$</span><span class="va">scale</span><span class="op">)</span> <span class="op">*</span> 
  <span class="fu"><a href="https://rdrr.io/r/base/drop.html">drop</a></span><span class="op">(</span><span class="va">fit</span><span class="op">$</span><span class="va">loadings</span> <span class="op">%*%</span> <span class="va">fit</span><span class="op">$</span><span class="va">betas</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/colnames.html">colnames</a></span><span class="op">(</span><span class="va">fit</span><span class="op">$</span><span class="va">loadings</span><span class="op">)</span><span class="op">]</span><span class="op">)</span>
<span class="va">betas</span>
<span class="co">#&gt;       age    height </span>
<span class="co">#&gt; 0.3291211 0.9552908</span></code></pre></div>
<p>위 계산은 함수 <code><a href="../reference/fit_pcr.html">fit_pcr()</a></code> 내에서 수행되어 결과값의 <code>org_betas</code> 원소에 저장된다.</p>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">fit</span><span class="op">$</span><span class="va">org_betas</span>
<span class="co">#&gt;  (Intercept)          age       height </span>
<span class="co">#&gt; -108.1671098    0.3291211    0.9552908</span></code></pre></div>
</div>
<div id="반응치의-예측" class="section level2" number="4.3">
<h2 class="hasAnchor">
<a href="#%EB%B0%98%EC%9D%91%EC%B9%98%EC%9D%98-%EC%98%88%EC%B8%A1" class="anchor"></a><span class="header-section-number">4.3</span> 반응치의 예측</h2>
<p>새로 관측된 독립변수에 대한 종속변수 예측을 수행하고자 할 때, 새 관측치에 대한 주성분 스코어를 구한 뒤 기존에 추정된 주성분 회귀모형에 대입하는 방식으로 수행한다.</p>
<p>위 나이/키/몸무게 데이터로 이루어진 회귀모형 예제에서, 나이가 40세이고 키가 170cm이며, 몸무게는 측정이 되지 않은 새로운 관측치가 있다고 하자.</p>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">new_obs</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://tibble.tidyverse.org/reference/tibble.html">tibble</a></span><span class="op">(</span>age <span class="op">=</span> <span class="fl">40</span>, height <span class="op">=</span> <span class="fl">170</span><span class="op">)</span></code></pre></div>
<p>새 관측치에 대한 주성분 스코어를 계산은, 주성분 분해 시 적용된 평균조정 및 분산조정을 그대로 적용한 뒤 가중치 행렬을 적용하는 방식으로 수행한다.</p>
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">new_obs</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://rdrr.io/r/base/scale.html">scale</a></span><span class="op">(</span>center <span class="op">=</span> <span class="va">fit</span><span class="op">$</span><span class="va">center</span>, scale <span class="op">=</span> <span class="va">fit</span><span class="op">$</span><span class="va">scale</span><span class="op">)</span> <span class="op">%*%</span>
  <span class="va">fit</span><span class="op">$</span><span class="va">loadings</span>
<span class="co">#&gt;             PC1       PC2</span>
<span class="co">#&gt; [1,] -0.5755606 0.3067933</span></code></pre></div>
<p>위 과정은 함수 <code><a href="../reference/predict_pca.html">predict_pca()</a></code>로 구현되어 있다.</p>
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">new_score</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/predict_pca.html">predict_pca</a></span><span class="op">(</span><span class="va">fit</span>, <span class="va">new_obs</span><span class="op">)</span>
<span class="va">new_score</span>
<span class="co">#&gt; # A tibble: 1 x 2</span>
<span class="co">#&gt;      PC1   PC2</span>
<span class="co">#&gt;    &lt;dbl&gt; &lt;dbl&gt;</span>
<span class="co">#&gt; 1 -0.576 0.307</span></code></pre></div>
<p>이 주성분 스코어를 함수 <code><a href="../reference/predict_linear_regression.html">predict_linear_regression()</a></code>의 입력 데이터로 사용할 때, 새 관측치에 대한 종속변수의 예측값을 얻을 수 있다.</p>
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="../reference/predict_linear_regression.html">predict_linear_regression</a></span><span class="op">(</span><span class="va">fit</span>, <span class="va">new_score</span>, <span class="fu"><a href="https://tidyselect.r-lib.org/reference/starts_with.html">starts_with</a></span><span class="op">(</span><span class="st">"PC"</span><span class="op">)</span><span class="op">)</span>
<span class="co">#&gt; # A tibble: 1 x 1</span>
<span class="co">#&gt;   .pred</span>
<span class="co">#&gt;   &lt;dbl&gt;</span>
<span class="co">#&gt; 1  67.4</span></code></pre></div>
<p>위 일련의 예측 수행 과정이 함수 <code><a href="../reference/predict_pcr.html">predict_pcr()</a></code>로 구현되어, 아래와 같이 사용할 수 있다.</p>
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="../reference/predict_pcr.html">predict_pcr</a></span><span class="op">(</span>
  <span class="va">fit</span>,
  .new_data <span class="op">=</span> <span class="va">new_obs</span>,
  .ci_interval <span class="op">=</span> <span class="fl">0.95</span>,
  .pi_interval <span class="op">=</span> <span class="fl">0.95</span>
<span class="op">)</span>
<span class="co">#&gt; # A tibble: 1 x 6</span>
<span class="co">#&gt;   .pred   .se .ci_lower .ci_upper .pi_lower .pi_upper</span>
<span class="co">#&gt;   &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;</span>
<span class="co">#&gt; 1  67.4  1.01      65.0      69.8      60.7      74.1</span></code></pre></div>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

      </div>

</div>



      <footer><div class="copyright">
  <p>Developed by Youngrok Lee.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.6.1.</p>
</div>

      </footer>
</div>

  


  </body>
</html>
