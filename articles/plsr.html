<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>부분최소자승 회귀분석 • dmtr</title>
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/css/bootstrap.min.css" integrity="sha256-bZLfwXAP04zRMK2BjiO8iu9pf4FbLqX6zitd+tIvLhE=" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="부분최소자승 회귀분석">
<meta property="og:description" content="dmtr">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body data-spy="scroll" data-target="#toc">
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">dmtr</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">0.0.0.9000</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">
    <span class="fas fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/discriminant-analysis.html">판별분석</a>
    </li>
    <li>
      <a href="../articles/logistic-regression.html">로지스틱 회귀분석</a>
    </li>
    <li>
      <a href="../articles/pca.html">주성분분석</a>
    </li>
    <li>
      <a href="../articles/plsr.html">부분최소자승 회귀분석</a>
    </li>
    <li>
      <a href="../articles/regression.html">회귀분석</a>
    </li>
    <li>
      <a href="../articles/tree.html">트리기반 기법</a>
    </li>
  </ul>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right"></ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><script src="plsr_files/header-attrs-2.9/header-attrs.js"></script><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>부분최소자승 회귀분석</h1>
            
      
      
      <div class="hidden name"><code>plsr.Rmd</code></div>

    </div>

    
    
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">dmtr</span><span class="op">)</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://dplyr.tidyverse.org">dplyr</a></span><span class="op">)</span></code></pre></div>
<div id="데이터" class="section level1" number="1">
<h1 class="hasAnchor">
<a href="#%EB%8D%B0%EC%9D%B4%ED%84%B0" class="anchor"></a><span class="header-section-number">1</span> 데이터</h1>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">biometric</span>, package <span class="op">=</span> <span class="st">"dmtr"</span><span class="op">)</span></code></pre></div>
<table class="table">
<caption>
<span id="tab:biometric-data-print">Table 1.1: </span>나이, 키, 몸무게 데이터</caption>
<thead><tr class="header">
<th align="right">age</th>
<th align="right">height</th>
<th align="right">weight</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="right">21</td>
<td align="right">170</td>
<td align="right">60</td>
</tr>
<tr class="even">
<td align="right">47</td>
<td align="right">167</td>
<td align="right">65</td>
</tr>
<tr class="odd">
<td align="right">36</td>
<td align="right">173</td>
<td align="right">67</td>
</tr>
<tr class="even">
<td align="right">15</td>
<td align="right">165</td>
<td align="right">54</td>
</tr>
<tr class="odd">
<td align="right">54</td>
<td align="right">168</td>
<td align="right">73</td>
</tr>
<tr class="even">
<td align="right">25</td>
<td align="right">177</td>
<td align="right">71</td>
</tr>
<tr class="odd">
<td align="right">32</td>
<td align="right">169</td>
<td align="right">68</td>
</tr>
<tr class="even">
<td align="right">18</td>
<td align="right">172</td>
<td align="right">62</td>
</tr>
<tr class="odd">
<td align="right">43</td>
<td align="right">171</td>
<td align="right">66</td>
</tr>
<tr class="even">
<td align="right">28</td>
<td align="right">175</td>
<td align="right">68</td>
</tr>
</tbody>
</table>
</div>
<div id="plsr-model" class="section level1" number="2">
<h1 class="hasAnchor">
<a href="#plsr-model" class="anchor"></a><span class="header-section-number">2</span> PLS 모형</h1>
<div id="하나의-종속변수에-대한-pls-회귀분석" class="section level2" number="2.1">
<h2 class="hasAnchor">
<a href="#%ED%95%98%EB%82%98%EC%9D%98-%EC%A2%85%EC%86%8D%EB%B3%80%EC%88%98%EC%97%90-%EB%8C%80%ED%95%9C-pls-%ED%9A%8C%EA%B7%80%EB%B6%84%EC%84%9D" class="anchor"></a><span class="header-section-number">2.1</span> 하나의 종속변수에 대한 PLS 회귀분석</h2>
<p>회귀분석에서와 같이 하나의 종속변수에 영향을 주는 <span class="math inline">\(k\)</span>개의 독립변수가 있다고 하자. 모든 변수는 평균조정되었다고 간주한다. 본 장에서 다루고자 하는 부분최소자승법(partial least squares: PLS)는 앞에서 다룬 주성분 회귀분석(PCR)과 유사하나, 도출되는 새로운 잠재변수들이 다르다.</p>
<p>종속변수가 하나만 존재하는 경우에는 데이터 행렬 <span class="math inline">\(\mathbf{X}\)</span>와 종속변수벡터 <span class="math inline">\(\mathbf{y}\)</span>가 동일한 잠재변수로 설명된다고 가정할 수 있다. <span class="math inline">\((n \times k)\)</span> 데이터 행렬 <span class="math inline">\(\mathbf{X}\)</span>와 종속변수벡터 <span class="math inline">\(\mathbf{y}\)</span>에 대하여 동시에 <span class="math inline">\(A\)</span>개의 잠재변수벡터 <span class="math inline">\(\mathbf{t}_1, \ldots, \mathbf{t}_A\)</span>로 설명하는 모형을 아래와 같이 기술해보자.</p>
<p><span class="math display" id="eq:plsr-y-single">\[\begin{eqnarray}
\mathbf{X} &amp;=&amp; \mathbf{t}_1 \mathbf{p}_1^\top + \mathbf{t}_2 \mathbf{p}_2^\top + \cdots + \mathbf{t}_A \mathbf{p}_A^\top + \mathbf{E} \tag{2.1}\\
\mathbf{y} &amp;=&amp; \mathbf{t}_1 b_1 + \mathbf{t}_2 b_2 + \cdots + \mathbf{t}_A b_A + \mathbf{f} \tag{2.2}
\end{eqnarray}\]</span></p>
<p>여기서 계수벡터 <span class="math inline">\(\mathbf{p}_a\)</span>는 <span class="math inline">\(\mathbf{X}\)</span>에 해당하는 로딩(loading)을, 그리고 계수 <span class="math inline">\(b_a\)</span>는 <span class="math inline">\(\mathbf{y}\)</span>에 해당하는 로딩을 나타내며, <span class="math inline">\(\mathbf{E}\)</span>와 <span class="math inline">\(\mathbf{f}\)</span>는 각 모형에 해당하는 오차항(행렬 또는 벡터)이다.</p>
<p>위 모형을 (<span class="math inline">\(n \times A\)</span>) 잠재변수 행렬 <span class="math inline">\(\mathbf{T} = \left[\mathbf{t}_1 \, \cdots \, \mathbf{t}_A \right]\)</span>와 <span class="math inline">\((k \times A)\)</span> 로딩행렬 <span class="math inline">\(\mathbf{P} = \left[\mathbf{p}_1 \, \cdots \, \mathbf{p}_A \right]\)</span>, 그리고 로딩벡터 <span class="math inline">\(\mathbf{b} = \left[b_1 \, \cdots \, b_A \right]^\top\)</span>을 이용하여 아래와 같이 행렬식으로 나타낼 수 있다.</p>
<p><span class="math display" id="eq:plsr-y-single-matrix">\[\begin{eqnarray}
\mathbf{X} &amp;=&amp; \mathbf{T}\mathbf{P}^\top + \mathbf{E} \tag{2.3}\\
\mathbf{y} &amp;=&amp; \mathbf{T}\mathbf{b} + \mathbf{f} \tag{2.4}
\end{eqnarray}\]</span></p>
<div id="plsr-single-nipals" class="section level3" number="2.1.1">
<h3 class="hasAnchor">
<a href="#plsr-single-nipals" class="anchor"></a><span class="header-section-number">2.1.1</span> NIPALS 알고리즘</h3>
<ul>
<li>
<strong>[단계 0]</strong> 반복알고리즘 수행을 위한 초기화를 한다. <span class="math inline">\(a \leftarrow 1\)</span>, <span class="math inline">\(\mathbf{X}_a \leftarrow \mathbf{X}\)</span>, <span class="math inline">\(\mathbf{y}_a \leftarrow \mathbf{y}\)</span>.</li>
<li>
<strong>[단계 1]</strong> <span class="math inline">\(\mathbf{X}_a\)</span>을 다중종속변수 행렬으로, <span class="math inline">\(\mathbf{y}_a\)</span>를 독립변수 벡터로 하는 회귀모형으로부터 기울기 <span class="math inline">\(\mathbf{w}_a = [w_{a1} \, \cdots \, w_{ak}]^\top\)</span>를 산출한다.
<span class="math display">\[\mathbf{w}_a \leftarrow \left. \mathbf{X}_a^\top \mathbf{y}_a \middle/ \mathbf{y}_a^\top \mathbf{y}_a \right.  \]</span>
</li>
<li>
<strong>[단계 2]</strong> 기울기 벡터 <span class="math inline">\(\mathbf{w}_a\)</span>의 크기가 1이 되도록 한다.
<span class="math display">\[\left. \mathbf{w}_a \leftarrow \mathbf{w}_a \middle/ \sqrt{\mathbf{w}_a^\top \mathbf{w}_a} \right.\]</span>
</li>
<li>
<strong>[단계 3]</strong> 잠재변수 <span class="math inline">\(\mathbf{t}_a\)</span>를 행렬 <span class="math inline">\(\mathbf{X}_a\)</span>의 각 열의 가중평균으로 구한다. 이 때, 가중치는 기울기 벡터 <span class="math inline">\(\mathbf{w}_a\)</span>를 이용한다.
<span class="math display">\[\mathbf{t}_a \leftarrow \mathbf{X}_a \mathbf{w}_a\]</span>
</li>
<li>
<strong>[단계 4]</strong> 식 <a href="#eq:plsr-x-single">(2.1)</a>와 같이 <span class="math inline">\(\mathbf{X}_a\)</span>을 다중종속변수 행렬으로, <span class="math inline">\(\mathbf{t}_a\)</span>를 독립변수 벡터로 하는 회귀모형으로부터 로딩벡터 <span class="math inline">\(\mathbf{p}_a\)</span>를 구한다.
<span class="math display">\[\mathbf{p}_a \leftarrow \left. \mathbf{X}_a^\top \mathbf{t}_a \middle/ \mathbf{t}_a^\top \mathbf{t}_a \right.\]</span>
</li>
<li>
<strong>[단계 5]</strong> 로딩벡터 <span class="math inline">\(\mathbf{p}_a\)</span>의 크기를 1로 조정하고, 잠재변수 벡터 <span class="math inline">\(\mathbf{t}_a\)</span>와 기울기 벡터 <span class="math inline">\(\mathbf{w}_a\)</span>의 크기를 그에 따라 보정한다.
<span class="math display">\[d \leftarrow \sqrt{\mathbf{p}_a^\top \mathbf{p}_a}, \, \mathbf{t}_a \leftarrow \mathbf{t}_a d, \, \mathbf{w}_a \leftarrow \mathbf{w}_a d, \, \mathbf{p}_a \leftarrow \frac{1}{d} \mathbf{p}_a \]</span>
</li>
<li>
<strong>[단계 6]</strong> 식 <a href="#eq:plsr-y-single">(2.2)</a>와 같이 잠재변수 <span class="math inline">\(\mathbf{t}_a\)</span>를 종속변수 <span class="math inline">\(\mathbf{y}_a\)</span>에 회귀시킬 때 계수 <span class="math inline">\(b_a\)</span>를 산출한다.
<span class="math display">\[b_a \leftarrow \left. \mathbf{y}_a^\top \mathbf{t}_a \middle/ \mathbf{t}_a^\top \mathbf{t}_a \right. \]</span>
</li>
<li>
<strong>[단계 7]</strong> 독립변수 행렬 <span class="math inline">\(\mathbf{X}_a\)</span>와 종속변수벡터 <span class="math inline">\(\mathbf{y}_a\)</span>로부터 새로 얻어진 잠재변수 벡터 <span class="math inline">\(\mathbf{t}_a\)</span>가 설명하는 부분을 제거하고 나머지 변동만을 담은 독립변수 행렬 <span class="math inline">\(\mathbf{X}_{a + 1}\)</span>과 종속변수벡터 <span class="math inline">\(\mathbf{y}_{a + 1}\)</span>을 구한다.
<span class="math display">\[\mathbf{X}_{a + 1} \leftarrow \mathbf{X}_a - \mathbf{t}_a \mathbf{p}_a^\top, \, \mathbf{y}_{a + 1} \leftarrow \mathbf{y}_a - \mathbf{t}_a b_a\]</span>
</li>
<li>
<strong>[단계 8]</strong> <span class="math inline">\(a \leftarrow a + 1\)</span>로 업데이트하고, [단계 1]로 돌아간다. [단계 1] - [단계 8]의 과정을 <span class="math inline">\(A\)</span>개의 잠재변수를 얻을 때까지 반복한다.</li>
</ul>
<p>위 반복 알고리즘은 함수는 <code><a href="../reference/nipals_plsr.html">nipals_plsr()</a></code>로 구현되어 있다.</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">y</span> <span class="op">&lt;-</span> <span class="va">biometric</span> <span class="op">%&gt;%</span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="va">weight</span><span class="op">)</span> <span class="op">%&gt;%</span> <span class="fu"><a href="https://rdrr.io/r/base/scale.html">scale</a></span><span class="op">(</span><span class="op">)</span>
<span class="va">X</span> <span class="op">&lt;-</span> <span class="va">biometric</span> <span class="op">%&gt;%</span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="va">age</span>, <span class="va">height</span><span class="op">)</span> <span class="op">%&gt;%</span> <span class="fu"><a href="https://rdrr.io/r/base/scale.html">scale</a></span><span class="op">(</span><span class="op">)</span>
<span class="va">plsr_fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/nipals_plsr.html">nipals_plsr</a></span><span class="op">(</span><span class="va">X</span>, <span class="va">y</span>, ncomp <span class="op">=</span> <span class="fl">2L</span><span class="op">)</span>
<span class="va">plsr_fit</span>
<span class="co">#&gt; $T</span>
<span class="co">#&gt;              LV1        LV2</span>
<span class="co">#&gt;  [1,] -0.7858087  0.3080356</span>
<span class="co">#&gt;  [2,]  0.3229184 -1.4835503</span>
<span class="co">#&gt;  [3,]  0.6295298  0.3450656</span>
<span class="co">#&gt;  [4,] -1.9750173 -0.5667679</span>
<span class="co">#&gt;  [5,]  0.9178231 -1.5567950</span>
<span class="co">#&gt;  [6,]  0.6082079  1.7210543</span>
<span class="co">#&gt;  [7,] -0.2725870 -0.3890125</span>
<span class="co">#&gt;  [8,] -0.6425632  0.8890449</span>
<span class="co">#&gt;  [9,]  0.7325346 -0.4071198</span>
<span class="co">#&gt; [10,]  0.4649624  1.1400451</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $W</span>
<span class="co">#&gt;              LV1        LV2</span>
<span class="co">#&gt; age    0.7992341 -0.6028787</span>
<span class="co">#&gt; height 0.6039375  0.7978329</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $P</span>
<span class="co">#&gt;              LV1        LV2</span>
<span class="co">#&gt; age    0.8321183 -0.6028787</span>
<span class="co">#&gt; height 0.5545982  0.7978329</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $b</span>
<span class="co">#&gt;       LV1       LV2 </span>
<span class="co">#&gt; 0.9937095 0.0417354 </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $ncomp</span>
<span class="co">#&gt; [1] 2</span></code></pre></div>
<p>회귀계수 <code>b</code>와 잠재변수 스코어 행렬 <code>T</code>, 그리고 종속변수에 적용된 평균 및 분산조정 수치를 이용하여, 아래와 같이 분산조정 이전의 종속변수에 대한 회귀식을 추정할 수 있다.</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span>
  <span class="fu"><a href="https://rdrr.io/r/base/attr.html">attr</a></span><span class="op">(</span><span class="va">y</span>, <span class="st">"scaled:center"</span><span class="op">)</span>,
  <span class="va">plsr_fit</span><span class="op">$</span><span class="va">b</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/attr.html">attr</a></span><span class="op">(</span><span class="va">y</span>, <span class="st">"scaled:scale"</span><span class="op">)</span> <span class="op">+</span> 
    <span class="fu"><a href="https://rdrr.io/r/base/colSums.html">rowSums</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/solve.html">solve</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/t.html">t</a></span><span class="op">(</span><span class="va">plsr_fit</span><span class="op">$</span><span class="cn">T</span><span class="op">)</span> <span class="op">%*%</span> <span class="va">plsr_fit</span><span class="op">$</span><span class="cn">T</span><span class="op">)</span> <span class="op">%*%</span> <span class="fu"><a href="https://rdrr.io/r/base/t.html">t</a></span><span class="op">(</span><span class="va">plsr_fit</span><span class="op">$</span><span class="cn">T</span><span class="op">)</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/attr.html">attr</a></span><span class="op">(</span><span class="va">y</span>, <span class="st">"scaled:center"</span><span class="op">)</span><span class="op">)</span>
<span class="op">)</span>
<span class="co">#&gt;     weight        LV1        LV2 </span>
<span class="co">#&gt; 65.4000000  5.5069003  0.2312876</span></code></pre></div>
<p>위 추정된 회귀식은 아래와 같이 잠재변수 스코어 행렬 <code>T</code>를 독립변수로 하여 평균조정 이전의 종속변수를 설명하는 회귀모형의 추정 결과이다.</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">T_A</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://tibble.tidyverse.org/reference/as_tibble.html">as_tibble</a></span><span class="op">(</span><span class="va">plsr_fit</span><span class="op">[[</span><span class="st">"T"</span><span class="op">]</span><span class="op">]</span><span class="op">)</span>
<span class="va">reg_data</span> <span class="op">&lt;-</span> <span class="va">biometric</span> <span class="op">%&gt;%</span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="va">weight</span><span class="op">)</span> <span class="op">%&gt;%</span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/bind.html">bind_cols</a></span><span class="op">(</span><span class="va">T_A</span><span class="op">)</span>
<span class="va">lm_fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/fit_linear_regression.html">fit_linear_regression</a></span><span class="op">(</span><span class="va">reg_data</span>, <span class="va">weight</span>, <span class="fu"><a href="https://tidyselect.r-lib.org/reference/all_of.html">all_of</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/names.html">names</a></span><span class="op">(</span><span class="va">T_A</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>
<span class="va">lm_fit</span>
<span class="co">#&gt; $betas</span>
<span class="co">#&gt; (Intercept)         LV1         LV2 </span>
<span class="co">#&gt;  65.4000020   5.5069325   0.2312937 </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $hessian</span>
<span class="co">#&gt;               (Intercept)           LV1           LV2</span>
<span class="co">#&gt; (Intercept)  2.000000e+01 -1.340594e-11  1.398881e-11</span>
<span class="co">#&gt; LV1         -1.340594e-11  1.494215e+01 -6.557255e-12</span>
<span class="co">#&gt; LV2          1.398881e-11 -6.557255e-12  2.105785e+01</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $mse</span>
<span class="co">#&gt; [1] 7.038464</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $df</span>
<span class="co">#&gt; [1] 7</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $se</span>
<span class="co">#&gt; (Intercept)         LV1         LV2 </span>
<span class="co">#&gt;   0.8389556   0.9706158   0.8176115 </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $sst</span>
<span class="co">#&gt; [1] 276.4</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $rsq</span>
<span class="co">#&gt; [1] 0.8217466</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $rsqadj</span>
<span class="co">#&gt; [1] 0.770817</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $n</span>
<span class="co">#&gt; [1] 10</span></code></pre></div>
<p>위 과정을 함수 <code><a href="../reference/fit_plsr.html">fit_plsr()</a></code>로 아래와 같이 실행할 수 있다.</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/fit_plsr.html">fit_plsr</a></span><span class="op">(</span><span class="va">biometric</span>, <span class="va">weight</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">age</span>, <span class="va">height</span><span class="op">)</span>, .ncomp <span class="op">=</span> <span class="fl">2L</span><span class="op">)</span></code></pre></div>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="../reference/ttest_linear_regression.html">ttest_linear_regression</a></span><span class="op">(</span><span class="va">fit</span><span class="op">)</span>
<span class="co">#&gt; # A tibble: 3 x 5</span>
<span class="co">#&gt;   term        estimate std_error t_statistic  p_value</span>
<span class="co">#&gt;   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;    &lt;dbl&gt;</span>
<span class="co">#&gt; 1 (Intercept)   65.4       0.839      78.0   1.50e-11</span>
<span class="co">#&gt; 2 LV1            5.51      0.971       5.67  7.56e- 4</span>
<span class="co">#&gt; 3 LV2            0.231     0.818       0.283 7.85e- 1</span></code></pre></div>
<p>위 부분최소자승 회귀분석에 단계별 선택방법을 적용할 경우, 첫 번째 잠재변수만을 독립변수로 사용한 회귀모형이 최종적으로 선택되며, 이 때의 수정결정계수가 두 개의 주성분을 모두 이용한 모형보다 높음을 확인할 수 있다.</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">selected_lv</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/select_variables_stepwise.html">select_variables_stepwise</a></span><span class="op">(</span><span class="va">reg_data</span>, <span class="va">weight</span>, <span class="fu"><a href="https://rdrr.io/r/base/names.html">names</a></span><span class="op">(</span><span class="va">T_A</span><span class="op">)</span><span class="op">)</span>
<span class="co">#&gt; Inital variable:  LV1 , p-value =  0.0003124394  &lt;  0.05 </span>
<span class="co">#&gt; Iteration  1 : forward selection - no additional variable gives statistically significant improvement of the fit.</span>
<span class="fu"><a href="../reference/fit_linear_regression.html">fit_linear_regression</a></span><span class="op">(</span><span class="va">reg_data</span>, <span class="va">weight</span>, <span class="fu"><a href="https://tidyselect.r-lib.org/reference/all_of.html">all_of</a></span><span class="op">(</span><span class="va">selected_lv</span><span class="op">)</span><span class="op">)</span>
<span class="co">#&gt; $betas</span>
<span class="co">#&gt; (Intercept)         LV1 </span>
<span class="co">#&gt;   65.399974    5.506908 </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $hessian</span>
<span class="co">#&gt;              (Intercept)          LV1</span>
<span class="co">#&gt; (Intercept) 2.000000e+01 1.057487e-11</span>
<span class="co">#&gt; LV1         1.057487e-11 1.494215e+01</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $mse</span>
<span class="co">#&gt; [1] 6.229061</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $df</span>
<span class="co">#&gt; [1] 8</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $se</span>
<span class="co">#&gt; (Intercept)         LV1 </span>
<span class="co">#&gt;   0.7892440   0.9131028 </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $sst</span>
<span class="co">#&gt; [1] 276.4</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $rsq</span>
<span class="co">#&gt; [1] 0.8197088</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $rsqadj</span>
<span class="co">#&gt; [1] 0.7971724</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $n</span>
<span class="co">#&gt; [1] 10</span></code></pre></div>
</div>
</div>
<div id="plsr-multivariate-target" class="section level2" number="2.2">
<h2 class="hasAnchor">
<a href="#plsr-multivariate-target" class="anchor"></a><span class="header-section-number">2.2</span> 다수의 종속변수의 경우</h2>
<p><span class="math inline">\(m\)</span>개의 종속변수가 존재하여, 종속변수 데이터가 벡터가 아닌 (<span class="math inline">\(n \times m\)</span>) 행렬</p>
<p><span class="math display">\[\mathbf{Y} = \left[ \mathbf{y}_1 \, \cdots \, \mathbf{y}_m \right]\]</span></p>
<p>으로 표현될 때, 각각의 종속변수에 대해 따로 잠재변수를 산출하기보다는, 여러 종속변수를 설명하는 공통의 잠재변수행렬 <span class="math inline">\(\mathbf{T}\)</span>를 산출하는 것이 합리적이라 할 수 있다.</p>
<p>앞 절의 모형을 일반화하여 아래와 같은 모형을 가정한다.</p>
<p><span class="math display" id="eq:plsr-inner-multivariate-matrix">\[\begin{eqnarray}
\mathbf{X} &amp;=&amp; \mathbf{T} \mathbf{P}^\top + \mathbf{E} \tag{2.5}\\
\mathbf{Y} &amp;=&amp; \mathbf{U} \mathbf{Q}^\top + \mathbf{F} \tag{2.6}\\
\mathbf{U} &amp;=&amp; \mathbf{T} \mathbf{B} + \mathbf{H}  \tag{2.7}
\end{eqnarray}\]</span></p>
<p>식 <a href="#eq:plsr-x-multivariate-matrix">(2.5)</a>의 모형은 앞서 하나의 종속변수의 경우에서 살펴본 모형식 <a href="#eq:plsr-x-single-matrix">(2.3)</a>와 동일하다. 식 <a href="#eq:plsr-y-multivariate-matrix">(2.6)</a>에서 <span class="math inline">\((n \times A)\)</span> 행렬 <span class="math inline">\(\mathbf{U}\)</span>는 <span class="math inline">\(\mathbf{Y}\)</span>를 설명하는 <span class="math inline">\(A\)</span>개의 잠재변수를 나타내는 행렬이며, <span class="math inline">\((m \times A)\)</span> 행렬 <span class="math inline">\(\mathbf{Q}\)</span>는 종속변수행렬 <span class="math inline">\(\mathbf{Y}\)</span>와 잠재변수행렬 <span class="math inline">\(\mathbf{U}\)</span>간의 선형관계를 나타내는 로딩행렬이다. 또한 식 <a href="#eq:plsr-inner-multivariate-matrix">(2.7)</a>는 잠재변수행렬 <span class="math inline">\(\mathbf{T}\)</span>와 <span class="math inline">\(\mathbf{U}\)</span>간의 선형관계를 나타내는데, 특히 <span class="math inline">\(\mathbf{B}\)</span>는 <span class="math inline">\((A \times A)\)</span> 대각행렬(diagonal matrix)로써, <span class="math inline">\(\mathbf{U}\)</span>와 <span class="math inline">\(\mathbf{T}\)</span>간에는 서로 대응하는 열 간에만 관계가 성립하며, 그 관계는 아래와 같다.</p>
<p><span class="math display">\[\begin{equation*}
\mathbf{u}_a = b_a \mathbf{t}_a + \mathbf{h}_a, \, a = 1, \cdots, A
\end{equation*}\]</span></p>
<p>이 때, <span class="math inline">\(b_a\)</span>는 행렬 <span class="math inline">\(\mathbf{B}\)</span>의 <span class="math inline">\(a\)</span>번째 대각 원소를 나타낸다.</p>
<p><span class="math display">\[\mathbf{B} = \left[ \begin{array}{c c c c}
b_{1} &amp; 0 &amp; \cdots &amp; 0\\
0 &amp; b_{2} &amp;  &amp; 0\\
\vdots &amp;  &amp; \ddots &amp; \vdots \\
0 &amp; 0 &amp; \cdots &amp; b_{A}
\end{array} \right]
\]</span></p>
<p>행렬 <span class="math inline">\(\mathbf{E}\)</span>, <span class="math inline">\(\mathbf{F}\)</span>, <span class="math inline">\(\mathbf{H}\)</span>는 오차항에 해당하는 행렬이다.</p>
<div id="plsr-multivariate-nipals" class="section level3" number="2.2.1">
<h3 class="hasAnchor">
<a href="#plsr-multivariate-nipals" class="anchor"></a><span class="header-section-number">2.2.1</span> NIPALS 알고리즘</h3>
<p>다수의 종속변수가 존재하는 경우에도 NIPALS 알고리즘을 이용하여 모형을 추정한다. 이때는 각 잠재변수 <span class="math inline">\(\mathbf{t}_a\)</span>를 추출할 때 추출한 잠재변수의 수렴 여부를 확인할 필요가 없었던 위 <a href="#plsr-single-nipals">2.1.1</a>절의 경우와는 달리, 각 잠재변수 <span class="math inline">\(\mathbf{t}_a\)</span>와 <span class="math inline">\(\mathbf{u}_a\)</span>를 추출하는 과정에서 반복적인(iterative) 기법으로 두 잠재변수 벡터들을 업데이트하며 수렴 여부를 확인하여야 한다.</p>
<ul>
<li>
<strong>[단계 0]</strong> 반복알고리즘 수행을 위한 초기화를 한다. <span class="math inline">\(a \leftarrow 1\)</span>, <span class="math inline">\(\mathbf{X}_a \leftarrow \mathbf{X}\)</span>, <span class="math inline">\(\mathbf{Y}_a \leftarrow \mathbf{Y}\)</span>.</li>
<li>
<strong>[단계 1]</strong> 종속변수 행렬 <span class="math inline">\(\mathbf{Y}_a\)</span>의 임의의 열 하나를 잠재변수 벡터 <span class="math inline">\(\mathbf{u}_a\)</span>로 선정한다.</li>
<li>
<strong>[단계 2]</strong> <span class="math inline">\(\mathbf{X}_a\)</span>을 다중종속변수 행렬으로, 잠재변수 <span class="math inline">\(\mathbf{u}_a\)</span>를 독립변수 벡터로 하는 회귀모형으로부터 기울기 <span class="math inline">\(\mathbf{w}_a = [w_{a1} \, \cdots \, w_{ak}]^\top\)</span>를 산출한다.
<span class="math display">\[\mathbf{w}_a \leftarrow \left. \mathbf{X}_a^\top \mathbf{u}_a \middle/ \mathbf{u}_a^\top \mathbf{u}_a \right.  \]</span>
</li>
<li>
<strong>[단계 3]</strong> 기울기 벡터 <span class="math inline">\(\mathbf{w}_a\)</span>의 크기가 1이 되도록 한다.
<span class="math display">\[\left. \mathbf{w}_a \leftarrow \mathbf{w}_a \middle/ \sqrt{\mathbf{w}_a^\top \mathbf{w}_a} \right.\]</span>
</li>
<li>
<strong>[단계 4]</strong> 잠재변수 <span class="math inline">\(\mathbf{t}_a\)</span>를 행렬 <span class="math inline">\(\mathbf{X}_a\)</span>의 각 열의 가중평균으로 구한다. 이 때, 가중치는 기울기 벡터 <span class="math inline">\(\mathbf{w}_a\)</span>를 이용한다.
<span class="math display">\[\mathbf{t}_a \leftarrow \mathbf{X}_a \mathbf{w}_a\]</span>
</li>
<li>
<strong>[단계 5]</strong> <span class="math inline">\(\mathbf{Y}_a\)</span>을 다중종속변수 행렬으로, 잠재변수 <span class="math inline">\(\mathbf{t}_a\)</span>를 독립변수 벡터로 하는 회귀모형으로부터 기울기 (로딩벡터) <span class="math inline">\(\mathbf{q}_a = [q_{a1} \, \cdots \, q_{am}]^\top\)</span>를 산출한다.
<span class="math display">\[\mathbf{q}_a \leftarrow \left. \mathbf{Y}_a^\top \mathbf{t}_a \middle/ \mathbf{t}_a^\top \mathbf{t}_a \right.  \]</span>
</li>
<li>
<strong>[단계 6]</strong> 기울기 벡터 <span class="math inline">\(\mathbf{q}_a\)</span>의 크기가 1이 되도록 한다.
<span class="math display">\[\left. \mathbf{q}_a \leftarrow \mathbf{q}_a \middle/ \sqrt{\mathbf{q}_a^\top \mathbf{q}_a} \right.\]</span>
</li>
<li>
<strong>[단계 7]</strong> 잠재변수 <span class="math inline">\(\mathbf{u}_a\)</span>를 행렬 <span class="math inline">\(\mathbf{Y}_a\)</span>의 각 열의 가중평균으로 구한다. 이 때, 가중치는 기울기 벡터 <span class="math inline">\(\mathbf{q}_a\)</span>를 이용한다.
<span class="math display">\[\mathbf{u}_a \leftarrow \mathbf{Y}_a \mathbf{q}_a\]</span>
</li>
<li>
<strong>[단계 8]</strong> (수렴 확인) [단계 2]에서 [단계 7]까지의 과정을 잠재변수 벡터 <span class="math inline">\(\mathbf{u}_a\)</span>의 모든 원소값이 수렴할 때까지 반복한다. 수렴이 확인되면 [단계 9]로 진행한다.</li>
<li>
<strong>[단계 9]</strong> <span class="math inline">\(\mathbf{t}_a\)</span>를 <span class="math inline">\(\mathbf{X}_a\)</span>에 회귀시켜, <span class="math inline">\(\mathbf{X}_a\)</span>을 다중종속변수 행렬으로, <span class="math inline">\(\mathbf{t}_a\)</span>를 독립변수 벡터로 하는 회귀모형으로부터 로딩벡터 <span class="math inline">\(\mathbf{p}_a\)</span>를 구한다.
<span class="math display">\[\mathbf{p}_a \leftarrow \left. \mathbf{X}_a^\top \mathbf{t}_a \middle/ \mathbf{t}_a^\top \mathbf{t}_a \right.\]</span>
</li>
<li>
<strong>[단계 10]</strong> 로딩벡터 <span class="math inline">\(\mathbf{p}_a\)</span>의 크기를 1로 조정하고, 잠재변수 벡터 <span class="math inline">\(\mathbf{t}_a\)</span>와 기울기 벡터 <span class="math inline">\(\mathbf{w}_a\)</span>의 크기를 그에 따라 보정한다.
<span class="math display">\[d \leftarrow \sqrt{\mathbf{p}_a^\top \mathbf{p}_a}, \, \mathbf{t}_a \leftarrow \mathbf{t}_a d, \, \mathbf{w}_a \leftarrow \mathbf{w}_a d, \, \mathbf{p}_a \leftarrow \frac{1}{d} \mathbf{p}_a \]</span>
</li>
<li>
<strong>[단계 11]</strong> 잠재변수벡터 <span class="math inline">\(\mathbf{u}_a\)</span>와 <span class="math inline">\(\mathbf{t}_a\)</span>간의 내부관계 계수 <span class="math inline">\(b_a\)</span>를 산출한다.
<span class="math display">\[b_a \leftarrow \left. \mathbf{u}_a^\top \mathbf{t}_a \middle/ \mathbf{t}_a^\top \mathbf{t}_a \right. \]</span>
</li>
<li>
<strong>[단계 12]</strong> 독립변수행렬 <span class="math inline">\(\mathbf{X}_a\)</span>와 종속변수행렬 <span class="math inline">\(\mathbf{Y}_a\)</span>로부터 새로 얻어진 잠재변수 벡터 <span class="math inline">\(\mathbf{t}_a\)</span>가 설명하는 부분을 제거하고 나머지 변동만을 담은 독립변수행렬 <span class="math inline">\(\mathbf{X}_{a + 1}\)</span>과 종속변수행렬 <span class="math inline">\(\mathbf{Y}_{a + 1}\)</span>을 구한다.
<span class="math display">\[\mathbf{X}_{a + 1} \leftarrow \mathbf{X}_a - \mathbf{t}_a \mathbf{p}_a^\top, \, \mathbf{Y}_{a + 1} \leftarrow \mathbf{Y}_a - b_a \mathbf{t}_a \mathbf{q}_a^\top \]</span>
</li>
<li>
<strong>[단계 13]</strong> <span class="math inline">\(a \leftarrow a + 1\)</span>로 업데이트하고, [단계 1]로 돌아간다. [단계 1] - [단계 13]의 과정을 <span class="math inline">\(A\)</span>개의 잠재변수를 얻을 때까지 반복한다.</li>
</ul>
<p>위 반복 알고리즘은 함수는 <code><a href="../reference/nipals_plsr_n.html">nipals_plsr_n()</a></code>으로 구현되어 있다.</p>
</div>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

      </div>

</div>



      <footer><div class="copyright">
  <p>Developed by Youngrok Lee.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.6.1.</p>
</div>

      </footer>
</div>

  


  </body>
</html>
