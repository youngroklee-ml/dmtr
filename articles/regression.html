<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>회귀분석 • dmtr</title>
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/css/bootstrap.min.css" integrity="sha256-bZLfwXAP04zRMK2BjiO8iu9pf4FbLqX6zitd+tIvLhE=" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="회귀분석">
<meta property="og:description" content="dmtr">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body data-spy="scroll" data-target="#toc">
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">dmtr</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">0.0.0.9000</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">
    <span class="fas fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/discriminant-analysis.html">판별분석</a>
    </li>
    <li>
      <a href="../articles/logistic-regression.html">로지스틱 회귀분석</a>
    </li>
    <li>
      <a href="../articles/pca.html">주성분분석</a>
    </li>
    <li>
      <a href="../articles/plsr.html">부분최소자승 회귀분석</a>
    </li>
    <li>
      <a href="../articles/regression.html">회귀분석</a>
    </li>
    <li>
      <a href="../articles/tree.html">트리기반 기법</a>
    </li>
  </ul>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right"></ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><script src="regression_files/header-attrs-2.11/header-attrs.js"></script><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>회귀분석</h1>
            
      
      
      <div class="hidden name"><code>regression.Rmd</code></div>

    </div>

    
    
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">dmtr</span><span class="op">)</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://dplyr.tidyverse.org">dplyr</a></span><span class="op">)</span></code></pre></div>
<div id="multiple-linear-regression-data" class="section level1" number="1">
<h1 class="hasAnchor">
<a href="#multiple-linear-regression-data" class="anchor"></a><span class="header-section-number">1</span> 데이터</h1>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">biometric</span>, package <span class="op">=</span> <span class="st">"dmtr"</span><span class="op">)</span></code></pre></div>
<table class="table">
<caption>
<span id="tab:biometric-data-print">Table 1.1: </span>나이, 키, 몸무게 데이터</caption>
<thead><tr class="header">
<th align="right">age</th>
<th align="right">height</th>
<th align="right">weight</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="right">21</td>
<td align="right">170</td>
<td align="right">60</td>
</tr>
<tr class="even">
<td align="right">47</td>
<td align="right">167</td>
<td align="right">65</td>
</tr>
<tr class="odd">
<td align="right">36</td>
<td align="right">173</td>
<td align="right">67</td>
</tr>
<tr class="even">
<td align="right">15</td>
<td align="right">165</td>
<td align="right">54</td>
</tr>
<tr class="odd">
<td align="right">54</td>
<td align="right">168</td>
<td align="right">73</td>
</tr>
<tr class="even">
<td align="right">25</td>
<td align="right">177</td>
<td align="right">71</td>
</tr>
<tr class="odd">
<td align="right">32</td>
<td align="right">169</td>
<td align="right">68</td>
</tr>
<tr class="even">
<td align="right">18</td>
<td align="right">172</td>
<td align="right">62</td>
</tr>
<tr class="odd">
<td align="right">43</td>
<td align="right">171</td>
<td align="right">66</td>
</tr>
<tr class="even">
<td align="right">28</td>
<td align="right">175</td>
<td align="right">68</td>
</tr>
</tbody>
</table>
</div>
<div id="multiple-linear-regression" class="section level1" number="2">
<h1 class="hasAnchor">
<a href="#multiple-linear-regression" class="anchor"></a><span class="header-section-number">2</span> 다중회귀모형 추정</h1>
<p>아래와 같이 <span class="math inline">\(n\)</span>개의 객체와 <span class="math inline">\(k\)</span>개의 독립변수(<span class="math inline">\(\mathbf{x}\)</span>)로 이루어지고 하나의 종속변수(<span class="math inline">\(y\)</span>)로 이루어진 선형 회귀모형을 정의하자.</p>
<p><span class="math display" id="eq:multiple-linear-regression">\[\begin{equation}
y_i = \beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots + \beta_k x_{ik} + \epsilon_i
\tag{2.1}
\end{equation}\]</span></p>
<p>이 때, 오차항 <span class="math inline">\(\epsilon_i\)</span>은 서로 독립이고 동일한 정규분포 <span class="math inline">\(N(0, \sigma^2)\)</span>을 따른다.</p>
<p>위 회귀모형은 아래와 같이 행렬의 연산으로 표한할 수 있다.</p>
<p><span class="math display" id="eq:multiple-linear-regression-matrix">\[\begin{equation}
\mathbf{y} = \mathbf{X} \boldsymbol{\beta} + \boldsymbol{\epsilon} \tag{2.2}
\end{equation}\]</span></p>
<p>이 때,</p>
<p><span class="math display">\[
\mathbf{y} = \left[ \begin{array}{c}
y_1 \\ y_2 \\ y_3 \\ \vdots \\ y_n
\end{array} \right]
\]</span></p>
<p><span class="math display">\[
\mathbf{X} = \left[ \begin{array}{c c c c c}
1 &amp; x_{11} &amp; x_{12} &amp; \cdots &amp; x_{1k}\\
1 &amp; x_{21} &amp; x_{22} &amp; \cdots &amp; x_{2k}\\
\vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
1 &amp; x_{n1} &amp; x_{n2} &amp; \cdots &amp; x_{nk}
\end{array} \right]
\]</span></p>
<p><span class="math display">\[
\boldsymbol{\beta} = \left[ \begin{array}{c}
\beta_0 \\ \beta_1 \\ \beta_2 \\ \vdots \\ \beta_k
\end{array} \right]
\]</span></p>
<p><span class="math display">\[
\boldsymbol{\epsilon} = \left[ \begin{array}{c}
\epsilon_1 \\ \epsilon_2 \\ \epsilon_3 \\ \vdots \\ \epsilon_n
\end{array} \right]
\]</span></p>
<p>로 정의되며,</p>
<p><span class="math display">\[
E[\boldsymbol{\epsilon}] = \mathbf{0}, \, Var[\boldsymbol{\epsilon}] = \sigma^2 \mathbf{I} 
\]</span></p>
<p>이다.</p>
</div>
<div id="regression-coefficient-estimate" class="section level1" number="3">
<h1 class="hasAnchor">
<a href="#regression-coefficient-estimate" class="anchor"></a><span class="header-section-number">3</span> 회귀계수추정</h1>
<p>다중회귀모형에서 회귀계수들의 추정은 최소자승법(least squares method)에 근거하고 있다. 최소화시킬 오차항의 제곱합 <span class="math inline">\(Q\)</span>는 다음과 같이 표현된다.</p>
<p><span class="math display">\[\begin{equation}
Q = \sum_{i = 1}^{n} \left(y_i - \left(\beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots + \beta_k x_{ik}\right) \right) ^ 2 
\end{equation}\]</span></p>
<p>최소자승법에 의한 회귀계수의 추정은 제곱합 <span class="math inline">\(Q\)</span>를 각 <span class="math inline">\(\beta_j\)</span>에 대하여 편미분하고 이를 0으로 하는 다음과 같은 연립방정식을 풀어 <span class="math inline">\(\hat{\beta}_j\)</span>들을 구하는 것이다.</p>
<p><span class="math display">\[\begin{eqnarray*}
\frac{\partial Q}{\partial \beta_0} &amp;=&amp; - 2 \sum_{i = 1}^{n} 1 \left(y_i - \left(\beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots + \beta_k x_{ik}\right) \right) = 0\\
\frac{\partial Q}{\partial \beta_j} &amp;=&amp; - 2 \sum_{i = 1}^{n} x_{ij} \left(y_i - \left(\beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots + \beta_k x_{ik}\right) \right) = 0, \, j = 1, \cdots, k
\end{eqnarray*}\]</span></p>
<p>여기에서</p>
<p><span class="math display">\[
x_{i0} = 1, \, i = 1, \cdots, n
\]</span></p>
<p>이라 하면, 위 오차항의 제곱합과 회귀계수에 대한 편미분식은 아래와 같이 정리할 수 있다.</p>
<p><span class="math display" id="eq:multiple-linear-regression-sse">\[\begin{equation}
Q = \sum_{i = 1}^{n} \left(y_i - \left(\beta_0 x_{i0} + \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots + \beta_k x_{ik}\right) \right) ^ 2 \tag{3.1}
\end{equation}\]</span></p>
<p><span class="math display" id="eq:multiple-linear-regression-gradient">\[\begin{equation}
\frac{\partial Q}{\partial \beta_j} = - 2 \sum_{i = 1}^{n} x_{ij} \left(y_i - \left(\beta_0 x_{i0} + \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots + \beta_k x_{ik}\right) \right), \, j = 0, \cdots, k \tag{3.2}
\end{equation}\]</span></p>
<p>식 <a href="#eq:multiple-linear-regression-gradient">(3.2)</a>는 아래와 같이 행렬식으로 표현할 수 있다.</p>
<p><span class="math display">\[
\mathbf{X}^\top \left( \mathbf{y} - \mathbf{X}\mathbf{\beta} \right)
\]</span></p>
<p>이를 다시 정리하면 아래와 같이 회귀계수를 추정할 수 있다.</p>
<p><span class="math display">\[\begin{eqnarray*}
- 2 \mathbf{X}^\top \left( \mathbf{y} - \mathbf{X}\hat{\mathbf{\beta}} \right) &amp;=&amp; 0\\
\mathbf{X}^\top \mathbf{y} &amp;=&amp; \mathbf{X}^\top \mathbf{X} \hat{\mathbf{\beta}}\\
\left(\mathbf{X}^\top \mathbf{X}\right) ^ {-1} \mathbf{X}^\top \mathbf{y} &amp;=&amp; \left(\mathbf{X}^\top \mathbf{X}\right) ^ {-1} \left(\mathbf{X}^\top \mathbf{X}\right) \hat{\mathbf{\beta}}\\
&amp;=&amp; \hat{\mathbf{\beta}}
\end{eqnarray*}\]</span></p>
<p>행렬식을 이용하여, 주어진 예제 데이터에서 나이와 키로써 몸부게를 설명하는 회귀모형을 추정해보자.</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">y</span> <span class="op">&lt;-</span> <span class="va">biometric</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/pull.html">pull</a></span><span class="op">(</span><span class="va">weight</span><span class="op">)</span>

<span class="va">X</span> <span class="op">&lt;-</span> <span class="va">biometric</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="va">age</span>, <span class="va">height</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>`(Intercept)` <span class="op">=</span> <span class="fl">1</span>, .before <span class="op">=</span> <span class="fl">1L</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">as.matrix</a></span><span class="op">(</span><span class="op">)</span>

<span class="va">beta_hat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/solve.html">solve</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/t.html">t</a></span><span class="op">(</span><span class="va">X</span><span class="op">)</span> <span class="op">%*%</span> <span class="va">X</span><span class="op">)</span> <span class="op">%*%</span> <span class="fu"><a href="https://rdrr.io/r/base/t.html">t</a></span><span class="op">(</span><span class="va">X</span><span class="op">)</span> <span class="op">%*%</span> <span class="va">y</span>

<span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="va">beta_hat</span><span class="op">)</span>
<span class="co">#&gt;                     [,1]</span>
<span class="co">#&gt; (Intercept) -108.1671993</span>
<span class="co">#&gt; age            0.3291212</span>
<span class="co">#&gt; height         0.9552913</span></code></pre></div>
<p>추정된 회귀계수에서 각 편미분값이 0을 확인해보자.</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/t.html">t</a></span><span class="op">(</span><span class="va">X</span><span class="op">)</span> <span class="op">%*%</span> <span class="op">(</span><span class="va">y</span> <span class="op">-</span> <span class="va">X</span> <span class="op">%*%</span> <span class="va">beta_hat</span><span class="op">)</span>
<span class="co">#&gt;                      [,1]</span>
<span class="co">#&gt; (Intercept) -2.596323e-11</span>
<span class="co">#&gt; age         -8.215011e-10</span>
<span class="co">#&gt; height      -4.399752e-09</span></code></pre></div>
<p>실제 얻어진 값은 정확히 0은 아니지만 0에 매우 근접하며, 정확히 0이 얻어지지 않는 이유는 컴퓨팅 측면의 문제로 볼 수 있다 (알고리즘, 소수점 표현 구조 등). 이러한 경우 <code><a href="https://dplyr.tidyverse.org/reference/near.html">dplyr::near()</a></code> 함수를 이용하여 수치가 목표 수치에 충분히 근접하여 있는지를 확인할 수 있으며, 위 회귀계수 편미분값의 경우 모두 0에 충분히 근접함을 확인할 수 있다.</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://dplyr.tidyverse.org/reference/near.html">near</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/t.html">t</a></span><span class="op">(</span><span class="va">X</span><span class="op">)</span> <span class="op">%*%</span> <span class="op">(</span><span class="va">y</span> <span class="op">-</span> <span class="va">X</span> <span class="op">%*%</span> <span class="va">beta_hat</span><span class="op">)</span>, <span class="fl">0</span><span class="op">)</span>
<span class="co">#&gt;             [,1]</span>
<span class="co">#&gt; (Intercept) TRUE</span>
<span class="co">#&gt; age         TRUE</span>
<span class="co">#&gt; height      TRUE</span></code></pre></div>
<p>위와 같은 회귀계수 추정과정을 함수 <code><a href="../reference/fit_linear_regression.html">fit_linear_regression()</a></code>으로 구현하였으며, 결과 리스트값에서 <code>betas</code> 원소가 추정된 회귀계수를 나타낸다.</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/fit_linear_regression.html">fit_linear_regression</a></span><span class="op">(</span><span class="va">biometric</span>, <span class="va">weight</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">age</span>, <span class="va">height</span><span class="op">)</span><span class="op">)</span>
<span class="va">fit</span><span class="op">$</span><span class="va">betas</span>
<span class="co">#&gt;  (Intercept)          age       height </span>
<span class="co">#&gt; -108.1274927    0.3291100    0.9550617</span></code></pre></div>
<p>위 추정된 회귀계수를 식 <a href="#eq:multiple-linear-regression-sse">(3.1)</a>에 대입하여 잔차제곱합(residual sum of squareds; <span class="math inline">\(SSE\)</span>)을 계산해보자.</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">sse</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="op">(</span><span class="va">y</span> <span class="op">-</span> <span class="op">(</span><span class="va">X</span> <span class="op">%*%</span> <span class="va">fit</span><span class="op">$</span><span class="va">beta</span><span class="op">)</span><span class="op">)</span> <span class="op">^</span> <span class="fl">2</span><span class="op">)</span>
<span class="va">sse</span>
<span class="co">#&gt; [1] 49.26926</span></code></pre></div>
<p>이 때, 식 <a href="#eq:multiple-linear-regression">(2.1)</a>의 오차항 <span class="math inline">\(\epsilon_i\)</span>의 분산 <span class="math inline">\(\sigma ^ 2\)</span>의 추정은 위 잔차제곱합을 자유도 <span class="math inline">\((n - k - 1)\)</span>로 나눈 잔차평균제곱합(mean sequared error; <span class="math inline">\(MSE\)</span>)을 이용한다.</p>
<p><span class="math display">\[
\hat{\sigma} ^ 2 = MSE = \frac{SSE}{n - k - 1}
\]</span></p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">mse</span> <span class="op">&lt;-</span> <span class="va">sse</span> <span class="op">/</span> <span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">X</span><span class="op">)</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/base/nrow.html">ncol</a></span><span class="op">(</span><span class="va">X</span><span class="op">)</span><span class="op">)</span>
<span class="va">mse</span>
<span class="co">#&gt; [1] 7.038465</span></code></pre></div>
<p>함수 <code><a href="../reference/fit_linear_regression.html">fit_linear_regression()</a></code>의 결과 리스트값에서 <code>mse</code> 원소가 잔차평균제곱값을 나타내며, <code>df</code> 원소가 자유도 <span class="math inline">\((n - k - 1)\)</span>을 나타낸다.</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">fit</span><span class="op">$</span><span class="va">mse</span>
<span class="co">#&gt; [1] 7.038465</span></code></pre></div>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">fit</span><span class="op">$</span><span class="va">df</span>
<span class="co">#&gt; [1] 7</span></code></pre></div>
<p>따라서, 이 두 결과값을 이용하여 잔차제곱합을 역으로 계산할 수 있다.</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">fit</span><span class="op">$</span><span class="va">mse</span> <span class="op">*</span> <span class="va">fit</span><span class="op">$</span><span class="va">df</span>
<span class="co">#&gt; [1] 49.26926</span></code></pre></div>
</div>
<div id="multiple-linear-regression-inference" class="section level1" number="4">
<h1 class="hasAnchor">
<a href="#multiple-linear-regression-inference" class="anchor"></a><span class="header-section-number">4</span> 모형에 따른 추론</h1>
<div id="회귀성-검정" class="section level2" number="4.1">
<h2 class="hasAnchor">
<a href="#%ED%9A%8C%EA%B7%80%EC%84%B1-%EA%B2%80%EC%A0%95" class="anchor"></a><span class="header-section-number">4.1</span> 회귀성 검정</h2>
<p>다중회귀모형에 있어서 유의성 검정, 즉 회귀성 검정은 독립변수의 기울기에 해당하는 모든 회귀계수(<span class="math inline">\(\beta_0\)</span>은 제외)가 0의 값을 갖는가 또는 그렇지 않은가를 검정하는 것이다. 귀무가설과 대립가설은 아래와 같다.</p>
<p><span class="math display">\[\begin{eqnarray*}
H_0 &amp;:&amp; \beta_1 = \beta_2 = \cdots = \beta_k = 0\\
H_1 &amp;:&amp; \beta_j \neq 0 \, \text{for at least one} \, j \in \{1, 2, \cdots, k\}
\end{eqnarray*}\]</span></p>
<p>독립변수의 기울기에 해당하는 회귀계수 중 적어도 하나가 0이 아니라고 판단되면 귀무가설이 기각되고 회귀성이 있다고 말하게 된다.</p>
<p>회귀성 검정을 위해, 앞 절에서 살펴본 잔차제곱합이며 <span class="math inline">\(SSE\)</span> 외에, 전체제곱합(total sum of squares; <span class="math inline">\(SST\)</span>)와 회귀제곱합(regression sum of squares; <span class="math inline">\(SSR\)</span>)을 아래와 같이 정의한다.</p>
<p><span class="math display">\[\begin{eqnarray*}
SST &amp;=&amp; \sum_{i = 1}^{n} \left(y_i - \bar{y}\right) ^ 2\\
SSR &amp;=&amp; \sum_{i = 1}^{n} \left(\hat{y}_i - \bar{y}\right) ^ 2
\end{eqnarray*}\]</span></p>
<p>이 때, <span class="math inline">\(\bar{y} = \frac{1}{n} \sum_{i = 1}^{n} y_i\)</span>는 관측치 <span class="math inline">\(y_i\)</span>의 평균을 나타낸다. <span class="math inline">\(SST\)</span>, <span class="math inline">\(SSR\)</span>, 그리고 <span class="math inline">\(SSE\)</span>는 아래와 같은 관계를 지닌다.</p>
<p><span class="math display">\[\begin{eqnarray*}
SST &amp;=&amp; \sum_{i = 1}^{n} \left(y_i - \bar{y}\right) ^ 2\\
&amp;=&amp; \sum_{i = 1}^{n} \left(y_i - \hat{y}_{i} +  \hat{y}_{i} - \bar{y}\right) ^ 2\\
&amp;=&amp; \sum_{i = 1}^{n} \left(\left(y_i - \hat{y}_{i}\right) +  \left(\hat{y}_{i} - \bar{y}\right)\right) ^ 2\\
&amp;=&amp; \sum_{i = 1}^{n} \left(y_i - \hat{y}_{i}\right) ^ 2 + \sum_{i = 1}^{n}  \left(\hat{y}_{i} - \bar{y}\right) ^ 2 + 2 \sum_{i = 1}^{n} \left(y_i - \hat{y}_{i}\right) \left(\hat{y}_{i} - \bar{y}\right)\\
&amp;=&amp; SSE + SSR + 2 \sum_{i = 1}^{n} \left(y_i - \hat{y}_{i}\right) \left(\hat{y}_{i} - \bar{y}\right)\\
&amp;=&amp; SSE + SSR
\end{eqnarray*}\]</span></p>
<p>여기에서 회귀제곱합 <span class="math inline">\(SSR\)</span>을 자유도 <span class="math inline">\(k\)</span>로 나눈 값을 아래와 같이 회귀평균제곱(<span class="math inline">\(MSR\)</span>)으로 아래와 같이 정의하고,</p>
<p><span class="math display">\[\begin{equation}
MSR = \frac{SSR}{k}
\end{equation}\]</span></p>
<p>검정통계량으로 다음과 같은 <span class="math inline">\(F\)</span>-값을 이용한다.</p>
<p><span class="math display">\[\begin{equation}
F_0 = \frac{MSR}{MSE}
\end{equation}\]</span></p>
<p>회귀성 검정의 귀무가설이 옳을 경우, 즉 모든 독립변수의 기울기에 해당하는 회귀계수가 0일 경우, 검정통계량 <span class="math inline">\(F_0\)</span>는 다음과 같은 F-분포를 따른다.</p>
<p><span class="math display">\[\begin{equation}
F_0 \sim F_{(k, n - k - 1)}, \, \text{if } \beta_1 = \beta_2 = \cdots = \beta_k = 0
\end{equation}\]</span></p>
<p>따라서, 다음과 같을 때 유의수준 <span class="math inline">\(\alpha\)</span>에서 가설 <span class="math inline">\(H_0\)</span>을 기각한다.</p>
<p><span class="math display">\[
F_0 &gt; F_{(\alpha, k, n - k - 1)}
\]</span></p>
<p>위 예제 데이터에서 추정된 회귀모형에 대해 회귀성 검정을 수행해보자.</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">sst</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="op">(</span><span class="va">y</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span><span class="op">)</span> <span class="op">^</span> <span class="fl">2</span><span class="op">)</span>
<span class="va">ssr</span> <span class="op">&lt;-</span> <span class="va">sst</span> <span class="op">-</span> <span class="va">fit</span><span class="op">$</span><span class="va">mse</span> <span class="op">*</span> <span class="va">fit</span><span class="op">$</span><span class="va">df</span>
<span class="va">msr</span> <span class="op">&lt;-</span> <span class="va">ssr</span> <span class="op">/</span> <span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html">ncol</a></span><span class="op">(</span><span class="va">X</span><span class="op">)</span> <span class="op">-</span> <span class="fl">1</span><span class="op">)</span>
<span class="va">f0</span> <span class="op">&lt;-</span> <span class="va">msr</span> <span class="op">/</span> <span class="va">fit</span><span class="op">$</span><span class="va">mse</span>
<span class="va">alpha</span> <span class="op">&lt;-</span> <span class="fl">0.05</span>
<span class="va">f_alpha</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Fdist.html">qf</a></span><span class="op">(</span><span class="va">alpha</span>, <span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html">ncol</a></span><span class="op">(</span><span class="va">X</span><span class="op">)</span> <span class="op">-</span> <span class="fl">1</span><span class="op">)</span>, <span class="va">fit</span><span class="op">$</span><span class="va">df</span>, lower.tail <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span>
<span class="va">f0</span> <span class="op">&gt;</span> <span class="va">f_alpha</span>
<span class="co">#&gt; [1] TRUE</span></code></pre></div>
<p>위 결과에서 귀무가설은 기각되며, 유의수준 0.05에서 유의한 모형이라 할 수 있다. 위 결과를 함수 <code><a href="../reference/anova_linear_regression.html">anova_linear_regression()</a></code>을 이용하여 분산분석표로 나타낼 수 있다.</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="../reference/anova_linear_regression.html">anova_linear_regression</a></span><span class="op">(</span><span class="va">fit</span><span class="op">)</span>
<span class="co">#&gt; # A tibble: 3 × 6</span>
<span class="co">#&gt;   source       df    ss     ms F_statistic  p_value</span>
<span class="co">#&gt;   &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;       &lt;dbl&gt;    &lt;dbl&gt;</span>
<span class="co">#&gt; 1 Model         2 227.  114.          16.1  0.00239</span>
<span class="co">#&gt; 2 Residuals     7  49.3   7.04        NA   NA      </span>
<span class="co">#&gt; 3 Total         9 276.   NA           NA   NA</span></code></pre></div>
</div>
<div id="개별-회귀계수에-대한-t-검정" class="section level2" number="4.2">
<h2 class="hasAnchor">
<a href="#%EA%B0%9C%EB%B3%84-%ED%9A%8C%EA%B7%80%EA%B3%84%EC%88%98%EC%97%90-%EB%8C%80%ED%95%9C-t-%EA%B2%80%EC%A0%95" class="anchor"></a><span class="header-section-number">4.2</span> 개별 회귀계수에 대한 <span class="math inline">\(t\)</span>-검정</h2>
<p>회귀계수벡터 <span class="math inline">\(\boldsymbol{\beta}\)</span>의 추정량은 다음과 같은 기대치와 분산-공분산행렬을 갖는 다변량 정규분포를 따른다.</p>
<p><span class="math display">\[\begin{eqnarray*}
E\left[\hat{\boldsymbol{\beta}}\right] &amp;=&amp; \boldsymbol{\beta}\\
Var\left[\hat{\boldsymbol{\beta}}\right] &amp;=&amp; \sigma^2 \left(\mathbf{X}^\top \mathbf{X}\right)^{-1}
\end{eqnarray*}\]</span></p>
<p>위 예제 데이터에 대하여 회귀계수벡터 추정량의 분산-공분산행렬을 구해보자.</p>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">fit</span><span class="op">$</span><span class="va">mse</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/solve.html">solve</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/t.html">t</a></span><span class="op">(</span><span class="va">X</span><span class="op">)</span> <span class="op">%*%</span> <span class="va">X</span><span class="op">)</span>
<span class="co">#&gt;              (Intercept)          age        height</span>
<span class="co">#&gt; (Intercept) 1774.3282944 -0.671107371 -10.264886484</span>
<span class="co">#&gt; age           -0.6711074  0.004794718   0.003035477</span>
<span class="co">#&gt; height       -10.2648865  0.003035477   0.059566812</span></code></pre></div>
<p>함수 <code><a href="../reference/fit_linear_regression.html">fit_linear_regression()</a></code>의 결과 리스트값에서 <code>hessian</code> 원소는 <span class="math inline">\(2 \mathbf{X}^\top \mathbf{X}\)</span> 값을 지니며, 따라서 <code>hessian</code> 원소를 2로 나누어 <span class="math inline">\(\mathbf{X}^\top \mathbf{X}\)</span>에 대입할 때 위와 동일한 분산-공분산행렬을 보인다.</p>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">fit</span><span class="op">$</span><span class="va">mse</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/solve.html">solve</a></span><span class="op">(</span><span class="va">fit</span><span class="op">$</span><span class="va">hessian</span> <span class="op">/</span> <span class="fl">2</span><span class="op">)</span>
<span class="co">#&gt;              (Intercept)          age        height</span>
<span class="co">#&gt; (Intercept) 1774.3282947 -0.671107371 -10.264886485</span>
<span class="co">#&gt; age           -0.6711074  0.004794718   0.003035477</span>
<span class="co">#&gt; height       -10.2648865  0.003035477   0.059566812</span></code></pre></div>
<p>참고로, <code>hessian</code> 행렬은 식 <a href="#eq:multiple-linear-regression-sse">(3.1)</a>의 오차항 제곱합 <span class="math inline">\(Q\)</span>를 최적화하는 과정에서 얻어지며, 오차항 제곱합 <span class="math inline">\(Q\)</span>의 식을 변형하면 <code>hessian</code> 행렬 또한 달라진다. 예를 들어, <span class="math inline">\(Q\)</span> 대신 <span class="math inline">\(\frac{1}{2}Q\)</span>를 최적화하게 되면, 최적해 <span class="math inline">\(\hat{\boldsymbol{\beta}}\)</span>는 동일하나 <code>hessian</code> 행렬은 <span class="math inline">\(2 \mathbf{X}^\top \mathbf{X}\)</span>가 아닌 <span class="math inline">\(\mathbf{X}^\top \mathbf{X}\)</span>로 얻어진다.</p>
<p>위 분산-공분산행렬에서 대각원소들은 각 회귀계수의 분산을 나타내며, 따라서 각 대각원소의 제곱근이 각 회귀계수의 표준오차(standard error; <span class="math inline">\(se\left(\hat{\beta}_j\right)\)</span>)를 나타낸다.</p>
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/diag.html">diag</a></span><span class="op">(</span><span class="va">fit</span><span class="op">$</span><span class="va">mse</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/solve.html">solve</a></span><span class="op">(</span><span class="va">fit</span><span class="op">$</span><span class="va">hessian</span> <span class="op">/</span> <span class="fl">2</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>
<span class="co">#&gt; (Intercept)         age      height </span>
<span class="co">#&gt;  42.1227764   0.0692439   0.2440631</span></code></pre></div>
<p>이 표본오차는 <code><a href="../reference/fit_linear_regression.html">fit_linear_regression()</a></code>의 결과 리스트의 <code>se</code> 원소에 저장되어 있다.</p>
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">fit</span><span class="op">$</span><span class="va">se</span>
<span class="co">#&gt; (Intercept)         age      height </span>
<span class="co">#&gt;  42.1227764   0.0692439   0.2440631</span></code></pre></div>
<p>이 때, <span class="math inline">\(\hat{\beta}_j\)</span>의 분포는 다음과 같다.</p>
<p><span class="math display">\[
\frac{\hat{\beta}_j - \beta_j}{se\left(\hat{\beta}_j\right)} \sim t_{(n - k - 1)}
\]</span></p>
<p>그러므로 <span class="math inline">\(\beta_j\)</span>에 대한 <span class="math inline">\(100(1 - \alpha)\%\)</span> 신뢰구간은 아래와 같다.</p>
<p><span class="math display">\[
\hat{\beta}_j \pm se\left(\hat{\beta}_j\right)t_{(\alpha/2, \, n - k - 1)}
\]</span></p>
<p>각각의 회귀계수(<span class="math inline">\(\beta_0\)</span> 포함)가 0의 값을 갖는가 또는 그렇지 않은가를 검정하기 위한 귀무가설과 대립가설은 아래와 같다.</p>
<p><span class="math display">\[\begin{eqnarray*}
H_0 &amp;:&amp; \beta_j = 0\\
H_1 &amp;:&amp; \beta_j \neq 0
\end{eqnarray*}\]</span></p>
<p>위 검정을 위해 검정통계량 <span class="math inline">\(t\)</span>-값을 이용한다.</p>
<p><span class="math display">\[
T_j = \frac{\hat{\beta}_j}{se\left(\hat{\beta}_j\right)}
\]</span></p>
<p>위 통계량은 <span class="math inline">\(\beta_j = 0\)</span>일 때 <span class="math inline">\(t_{(n - k - 1)}\)</span> 분포를 따르기 때문에, 유의수준 <span class="math inline">\(0 &lt; \alpha &lt; 1\)</span>에서</p>
<p><span class="math display">\[
\left| T_j \right| &gt; t_{(2 / \alpha, \, n - k - 1)}
\]</span></p>
<p>이면 귀무가설 <span class="math inline">\(H_0\)</span>를 기각하게 된다.</p>
<p>위 예제 데이터에서 추정된 회귀모형의 회귀계수 각각에 대해 검정을 수행해보자.</p>
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">alpha</span> <span class="op">&lt;-</span> <span class="fl">0.05</span>
<span class="va">t_stat</span> <span class="op">&lt;-</span> <span class="va">fit</span><span class="op">$</span><span class="va">betas</span> <span class="op">/</span> <span class="va">fit</span><span class="op">$</span><span class="va">se</span>
<span class="va">t_alpha</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/TDist.html">qt</a></span><span class="op">(</span><span class="va">alpha</span> <span class="op">/</span> <span class="fl">2</span>, <span class="va">fit</span><span class="op">$</span><span class="va">df</span>, lower.tail <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">abs</a></span><span class="op">(</span><span class="va">t_stat</span><span class="op">)</span> <span class="op">&gt;</span> <span class="va">t_alpha</span>
<span class="co">#&gt; (Intercept)         age      height </span>
<span class="co">#&gt;        TRUE        TRUE        TRUE</span></code></pre></div>
<p>위 결과에서 모든 각각의 회귀계수에 대해 귀무가설은 기각되며, 유의수준 0.05에서 각 독립변수는 종속변수인 몸무게에 유의한 변수라는 것을 의미한다. 위 결과를 함수 <code><a href="../reference/ttest_linear_regression.html">ttest_linear_regression()</a></code>을 이용하여 데이터 프레임으로 나타낼 수 있다.</p>
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="../reference/ttest_linear_regression.html">ttest_linear_regression</a></span><span class="op">(</span><span class="va">fit</span><span class="op">)</span>
<span class="co">#&gt; # A tibble: 3 × 5</span>
<span class="co">#&gt;   term        estimate std_error t_statistic p_value</span>
<span class="co">#&gt;   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;   &lt;dbl&gt;</span>
<span class="co">#&gt; 1 (Intercept) -108.      42.1          -2.57 0.0372 </span>
<span class="co">#&gt; 2 age            0.329    0.0692        4.75 0.00208</span>
<span class="co">#&gt; 3 height         0.955    0.244         3.91 0.00580</span></code></pre></div>
</div>
<div id="개별-기울기-회귀계수에-대한-f-검정" class="section level2" number="4.3">
<h2 class="hasAnchor">
<a href="#%EA%B0%9C%EB%B3%84-%EA%B8%B0%EC%9A%B8%EA%B8%B0-%ED%9A%8C%EA%B7%80%EA%B3%84%EC%88%98%EC%97%90-%EB%8C%80%ED%95%9C-f-%EA%B2%80%EC%A0%95" class="anchor"></a><span class="header-section-number">4.3</span> 개별 기울기 회귀계수에 대한 <span class="math inline">\(F\)</span>-검정</h2>
<p><span class="math inline">\(r\)</span>개의 독립변수 <span class="math inline">\(x_1, x_2, \cdots, x_r\)</span>이 포함된 다중회귀모형에서 변수 <span class="math inline">\(x_j\)</span>에 대한 Type <span class="math inline">\(\text{II}\)</span> 제곱합이란, <span class="math inline">\(x_j\)</span>를 제외한 타 변수가 이미 포함된 모형에 <span class="math inline">\(x_j\)</span>가 추가로 도입될 때 증가되는 회귀제곱합을 의미한다.</p>
<p><span class="math display">\[
\Delta SSR(x_j \, | \, x_1, \cdots, x_{j - 1}, x_{j + 1}, \cdots, x_{r}) = SSR(x_1, \cdots, x_{r}) - SSR(x_1, \cdots, x_{j - 1}, x_{j + 1}, \cdots, x_{r})
\]</span></p>
<p>여기서 <span class="math inline">\(SSR(x_1, \cdots, x_{r})\)</span>은 변수 <span class="math inline">\(x_1, \cdots, x_{r}\)</span>이 포함된 모형의 회귀제곱합(<span class="math inline">\(SSR\)</span>)을 말한다.</p>
<p>위 예제에 대한 완전회귀모형에서 독립변수 <code>age</code>에 대한 Type <span class="math inline">\(\text{II}\)</span> 제곱합을 계산해보자.</p>
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">ssr</span> <span class="op">&lt;-</span> <span class="va">fit</span><span class="op">$</span><span class="va">sst</span> <span class="op">*</span> <span class="va">fit</span><span class="op">$</span><span class="va">rsq</span>
<span class="va">fit_without_age</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/fit_linear_regression.html">fit_linear_regression</a></span><span class="op">(</span><span class="va">biometric</span>, <span class="va">weight</span>, <span class="va">height</span><span class="op">)</span>
<span class="va">ssr_without_age</span> <span class="op">&lt;-</span> <span class="va">fit_without_age</span><span class="op">$</span><span class="va">sst</span> <span class="op">*</span> <span class="va">fit_without_age</span><span class="op">$</span><span class="va">rsq</span>
<span class="va">type2_age</span> <span class="op">&lt;-</span> <span class="va">ssr</span> <span class="op">-</span> <span class="va">ssr_without_age</span>
<span class="va">type2_age</span>
<span class="co">#&gt; [1] 159.0108</span></code></pre></div>
<p>Type <span class="math inline">\(\text{II}\)</span> 제곱합의 유의성 검정은 <span class="math inline">\(F\)</span> 검정을 통하여 이루어진다. 변수 <span class="math inline">\(x_j\)</span>에 대한 <span class="math inline">\(F\)</span>-값은 다음과 같이 산출된다.</p>
<p><span class="math display">\[
\Delta F_j = \frac{\Delta SSR(x_j \, | \, x_1, \cdots, x_{j - 1}, x_{j + 1}, \cdots, x_{r})}{MSE(x_1, \cdots, x_{r})}
\]</span></p>
<p>여기에서 <span class="math inline">\(MSE(x_1, \cdots, x_{r})\)</span>은 변수 <span class="math inline">\(x_1, \cdots, x_{r}\)</span>이 포함된 모형의 잔차평균제곱(<span class="math inline">\(MSE\)</span>)을 말한다.</p>
<p>변수 <span class="math inline">\(x_1, \cdots, x_{r}\)</span>이 포함된 모형에 대해 아래와 같은 회귀계수 검정을 수행한다 하자.</p>
<p><span class="math display">\[\begin{eqnarray*}
H_0 &amp;:&amp; \beta_j = 0\\
H_1 &amp;:&amp; \beta_j \neq 0
\end{eqnarray*}\]</span></p>
<p>귀무가설 <span class="math inline">\(H_0\)</span>가 참일 때, <span class="math inline">\(\Delta F_j\)</span>는 아래와 같은 <span class="math inline">\(F\)</span> 분포를 따른다.</p>
<p><span class="math display">\[
\Delta F_j \sim F_{(1, n - r + 1)}
\]</span></p>
<p>따라서, 각 변수의 회귀계수에 대한 유의수준 <span class="math inline">\(\alpha\)</span>에서의 <span class="math inline">\(F\)</span> 검정은, <span class="math inline">\(\Delta F_j &gt; F(\alpha, 1, n - r + 1)\)</span>일 때 귀무가설을 기각하여 변수 <span class="math inline">\(x_j\)</span>가 유의한 설명력을 지닌다고 판단한다.
위 예에서 변수 <code>age</code>에 대한 <span class="math inline">\(F\)</span>-값을 구한 뒤, <span class="math inline">\(F\)</span> 검정을 수행해보자.</p>
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">alpha</span> <span class="op">&lt;-</span> <span class="fl">0.05</span>
<span class="va">f_age</span> <span class="op">&lt;-</span> <span class="va">type2_age</span> <span class="op">/</span> <span class="va">fit</span><span class="op">$</span><span class="va">mse</span>
<span class="va">f_age</span> <span class="op">&gt;</span> <span class="fu"><a href="https://rdrr.io/r/stats/Fdist.html">qf</a></span><span class="op">(</span><span class="va">alpha</span>, <span class="fl">1</span>, <span class="va">fit</span><span class="op">$</span><span class="va">df</span>, lower.tail <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span>
<span class="co">#&gt; [1] TRUE</span></code></pre></div>
<p>위 결과에서, 유의수준 0.05에서 귀무가설은 기각되며, 따라서 <code>height</code> 변수가 이미 존재하는 모형에 <code>age</code> 변수를 추가할 때 종속변수를 추가로 유의하게 설명한다 할 수 있다.</p>
<p>이와 같은 <span class="math inline">\(F\)</span> 검정을 회귀모형의 모든 각각의 변수에 수행하는 함수 <code><a href="../reference/test_type2_linear_regression.html">test_type2_linear_regression()</a></code>을 아래와 같이 사용할 수 있다.</p>
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="../reference/test_type2_linear_regression.html">test_type2_linear_regression</a></span><span class="op">(</span><span class="va">biometric</span>, <span class="va">weight</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">age</span>, <span class="va">height</span><span class="op">)</span><span class="op">)</span>
<span class="co">#&gt; # A tibble: 2 × 4</span>
<span class="co">#&gt;   terms     ss F_statistic p_value</span>
<span class="co">#&gt;   &lt;chr&gt;  &lt;dbl&gt;       &lt;dbl&gt;   &lt;dbl&gt;</span>
<span class="co">#&gt; 1 age     159.        22.6 0.00208</span>
<span class="co">#&gt; 2 height  108.        15.3 0.00579</span></code></pre></div>
</div>
</div>
<div id="변수-선택" class="section level1" number="5">
<h1 class="hasAnchor">
<a href="#%EB%B3%80%EC%88%98-%EC%84%A0%ED%83%9D" class="anchor"></a><span class="header-section-number">5</span> 변수 선택</h1>
<p>종속변수를 설명하기 위한 독립변수들의 후보가 매우 많은 경우, 어떤 독립변수들의 조합에 의한 회귀모형이 가장 좋은가를 판단한다.</p>
<div id="모형-성능-척도" class="section level2" number="5.1">
<h2 class="hasAnchor">
<a href="#%EB%AA%A8%ED%98%95-%EC%84%B1%EB%8A%A5-%EC%B2%99%EB%8F%84" class="anchor"></a><span class="header-section-number">5.1</span> 모형 성능 척도</h2>
<p>고려하고 있는 회귀모형 또는 추정된 회귀식이 얼마나 데이터를 잘 반영하고 있는가를 알기 위해, 회귀모형의 결정계수(coefficient of determination) <span class="math inline">\(R ^ 2\)</span>를 아래와 같이 정의한다.</p>
<p><span class="math display">\[
R ^ 2 = \frac{SSR}{SST} = 1 - \frac{SSE}{SST}
\]</span></p>
<p>즉, <span class="math inline">\(R ^ 2\)</span>값은 전체제곱합 중 모형이 설명하는 제곱합의 비율로 해석되며, 0에서 1 사이의 값을 갖는다. 위 예제 데이터에서 추정된 회귀모형의 결정계수 값을 계산해보자.</p>
<div class="sourceCode" id="cb23"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">sst</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="op">(</span><span class="va">y</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span><span class="op">)</span> <span class="op">^</span> <span class="fl">2</span><span class="op">)</span>
<span class="fl">1</span> <span class="op">-</span> <span class="op">(</span><span class="va">fit</span><span class="op">$</span><span class="va">mse</span> <span class="op">*</span> <span class="va">fit</span><span class="op">$</span><span class="va">df</span><span class="op">)</span> <span class="op">/</span> <span class="va">sst</span>
<span class="co">#&gt; [1] 0.8217465</span></code></pre></div>
<p>이 식에서, <span class="math inline">\(SSE\)</span>는 독립변수의 개수가 증가함에 따라 감소하는 속성을 지니며, <span class="math inline">\(SST\)</span>는 독립변수의 개수와 상관없이 일정하므로, <span class="math inline">\(R ^ 2\)</span>는 독립변수 개수가 증가함에 따라 증가하는 속성을 지닌다. <span class="math inline">\(R ^ 2\)</span>에 기반한 모형 평가는 종종 과적합(overfitting)의 문제를 수반하므로, 독립변수 개수에 따른 <span class="math inline">\(R ^ 2\)</span>의 증가분에 대한 조정을 적용하는 수정결정계수(adjusted coefficient of determination) <span class="math inline">\(R_{adj} ^ 2\)</span>가 아래와 같이 정의된다.</p>
<p><span class="math display">\[
R_{adj} ^ 2 = 1 - \frac{SSE / (n - k - 1)}{SST / (n - 1)}
\]</span></p>
<p>여기에서 분자 <span class="math inline">\(SSE / (n - k - 1)\)</span>은 앞 절에서 살펴본 잔차평균제곱합 <span class="math inline">\(MSE\)</span> 이며, 분모는 <span class="math inline">\(SST\)</span>를 그 자유도 <span class="math inline">\(n - 1\)</span>으로 나눈 값이다.</p>
<div class="sourceCode" id="cb24"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fl">1</span> <span class="op">-</span> <span class="va">fit</span><span class="op">$</span><span class="va">mse</span> <span class="op">/</span> <span class="op">(</span><span class="va">sst</span> <span class="op">/</span> <span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span> <span class="op">-</span> <span class="fl">1</span><span class="op">)</span><span class="op">)</span>
<span class="co">#&gt; [1] 0.770817</span></code></pre></div>
<p>위 결정계수 <span class="math inline">\(R ^ 2\)</span> 및 수정결정계수 <span class="math inline">\(R_{adj} ^ 2\)</span>는 아래와 같이 <code><a href="../reference/fit_linear_regression.html">fit_linear_regression()</a></code> 결과 리스트의 <code>rsq</code> 및 <code>rsqadj</code> 원소에 각각 저장된다.</p>
<div class="sourceCode" id="cb25"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="va">fit</span><span class="op">$</span><span class="va">rsq</span><span class="op">)</span>
<span class="co">#&gt; [1] 0.8217465</span>
<span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="va">fit</span><span class="op">$</span><span class="va">rsqadj</span><span class="op">)</span>
<span class="co">#&gt; [1] 0.770817</span></code></pre></div>
<p>부가적인 모형의 성능척도로, 맬로우즈(Mallows)가 개발한 <span class="math inline">\(C_p\)</span> 통계량이 종종 사용된다. 이는 <span class="math inline">\(p\)</span>항 회귀모형이 완전모형에 얼마나 가까운지를 나타내는 척도로서, 다음과 같이 정의된다.</p>
<p><span class="math display">\[
C_p = \frac{SSE_p}{MSE} - n + 2p
\]</span></p>
<p>여기에서 <span class="math inline">\(MSE\)</span>는 <span class="math inline">\(k + 1\)</span>개의 회귀계수((<span class="math inline">\(k\)</span>개의 기울기 계수와 1개의 절편)를 이용한 완전모형에서 얻어지는 <span class="math inline">\(\sigma^2\)</span>의 추정량이며, <span class="math inline">\(SSE_p\)</span>는 <span class="math inline">\((p - 1)\)</span>개의 독립변수에 대한 회귀계수와 1개의 절편으로 이루어진 모형을 추정할 때 얻어지는 잔차제곱합이다 (<span class="math inline">\(p - 1 &lt; k\)</span>).</p>
<p>예를 들어, 위 예제 데이터에서 나이를 제외하고 키 하나의 변수만을 이용하여 몸무게를 설명하는 회귀모형을 아래와 같이 추정해보자.</p>
<div class="sourceCode" id="cb26"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">fit_reduced</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/fit_linear_regression.html">fit_linear_regression</a></span><span class="op">(</span><span class="va">biometric</span>, <span class="va">weight</span>, <span class="va">height</span><span class="op">)</span></code></pre></div>
<p>이 때, <span class="math inline">\(C_p\)</span>값은 아래와 같이 얻어진다.</p>
<div class="sourceCode" id="cb27"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="op">(</span><span class="va">fit_reduced</span><span class="op">$</span><span class="va">mse</span> <span class="op">*</span> <span class="va">fit_reduced</span><span class="op">$</span><span class="va">df</span><span class="op">)</span> <span class="op">/</span> <span class="va">fit</span><span class="op">$</span><span class="va">mse</span> <span class="op">-</span> 
  <span class="va">fit_reduced</span><span class="op">$</span><span class="va">n</span> <span class="op">+</span> <span class="fl">2</span> <span class="op">*</span> <span class="op">(</span><span class="va">fit_reduced</span><span class="op">$</span><span class="va">n</span> <span class="op">-</span> <span class="va">fit_reduced</span><span class="op">$</span><span class="va">df</span><span class="op">)</span>
<span class="co">#&gt; [1] 23.59169</span></code></pre></div>
<p>참고로, <span class="math inline">\(C_p\)</span>는 다음과 같은 예측치 평균오차제곱의 추정량이다.</p>
<p><span class="math display">\[
\Gamma_p = \frac{1}{\sigma^2} \sum_{i = i}^{n} E\left[\left(\hat{y}_i - E\left[y_i\right]\right)^2\right]
\]</span></p>
<p>완전모형(<span class="math inline">\(p = k + 1\)</span>)에 대한 <span class="math inline">\(C_p\)</span>값은 <span class="math inline">\(k + 1 = p\)</span>이다. 또한, <span class="math inline">\(p\)</span>항 회귀모형이 완전모형에 비해 편의(bias)가 없다면, <span class="math inline">\(C_p\)</span>의 기대값은 <span class="math inline">\(p\)</span>가 된다.</p>
<p><span class="math display">\[\begin{eqnarray*}
E\left[C_p \, | \, bias = 0\right] &amp;\approx&amp; \frac{E\left[SSE_p \, | \, bias = 0\right]}{\sigma^2} - n + 2p\\
&amp;=&amp; \frac{(n - p)\sigma^2}{\sigma^2} - n + 2p\\
&amp;=&amp; p
\end{eqnarray*}\]</span></p>
<p><span class="math inline">\(C_p\)</span>값이 <span class="math inline">\(p\)</span>에 가까울수록 편의가 적은 모형이며, 편의가 적은 모형인 동시에 변수의 수가 적은 모형이 가장 적절한 모형이라 할 수 있다.</p>
</div>
<div id="모든-가능한-조합의-회귀분석" class="section level2" number="5.2">
<h2 class="hasAnchor">
<a href="#%EB%AA%A8%EB%93%A0-%EA%B0%80%EB%8A%A5%ED%95%9C-%EC%A1%B0%ED%95%A9%EC%9D%98-%ED%9A%8C%EA%B7%80%EB%B6%84%EC%84%9D" class="anchor"></a><span class="header-section-number">5.2</span> 모든 가능한 조합의 회귀분석</h2>
<p>이 방법은 모든 가능한 독립변수들의 조합에 대한 회귀모형을 분석하여 가장 적합한 회귀모형을 선택하는 방법이다.</p>
<div class="sourceCode" id="cb28"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">variables</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"age"</span>, <span class="st">"height"</span><span class="op">)</span>
<span class="va">variables_in_model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/vector.html">vector</a></span><span class="op">(</span><span class="st">"list"</span>, length <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">variables</span><span class="op">)</span><span class="op">)</span>
<span class="kw">for</span><span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span>from <span class="op">=</span> <span class="fl">0L</span>, to <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">variables</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span>
  <span class="va">variables_in_model</span><span class="op">[[</span><span class="va">i</span> <span class="op">+</span> <span class="fl">1L</span><span class="op">]</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/utils/combn.html">combn</a></span><span class="op">(</span><span class="va">variables</span>, <span class="va">i</span>, simplify <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span>
<span class="op">}</span>

<span class="va">variables_in_model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/unlist.html">unlist</a></span><span class="op">(</span><span class="va">variables_in_model</span>, recursive <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span>
<span class="va">fit_reduced</span> <span class="op">&lt;-</span> <span class="fu">purrr</span><span class="fu">::</span><span class="fu"><a href="https://purrr.tidyverse.org/reference/map.html">map</a></span><span class="op">(</span>
  <span class="va">variables_in_model</span>,
  <span class="op">~</span> <span class="fu"><a href="../reference/fit_linear_regression.html">fit_linear_regression</a></span><span class="op">(</span><span class="va">biometric</span>, <span class="va">weight</span>, <span class="va">.x</span><span class="op">)</span>
<span class="op">)</span>
<span class="co">#&gt; Note: Using an external vector in selections is ambiguous.</span>
<span class="co">#&gt; ℹ Use `all_of(.x)` instead of `.x` to silence this message.</span>
<span class="co">#&gt; ℹ See &lt;https://tidyselect.r-lib.org/reference/faq-external-vector.html&gt;.</span>
<span class="co">#&gt; This message is displayed once per session.</span>
<span class="fu">purrr</span><span class="fu">::</span><span class="fu"><a href="https://purrr.tidyverse.org/reference/map.html">map_dfr</a></span><span class="op">(</span>
  <span class="va">fit_reduced</span>,
  <span class="op">~</span> <span class="fu"><a href="https://tibble.tidyverse.org/reference/tibble.html">tibble</a></span><span class="op">(</span>
    p <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">.x</span><span class="op">$</span><span class="va">betas</span><span class="op">)</span>,
    rsq <span class="op">=</span> <span class="va">.x</span><span class="op">$</span><span class="va">rsq</span>,
    rsqadj <span class="op">=</span> <span class="va">.x</span><span class="op">$</span><span class="va">rsqadj</span>,
    cp <span class="op">=</span> <span class="fu"><a href="../reference/mallows_c.html">mallows_c</a></span><span class="op">(</span><span class="va">.x</span>, <span class="va">fit</span><span class="op">)</span>,
    mse <span class="op">=</span> <span class="va">.x</span><span class="op">$</span><span class="va">mse</span>,
    terms <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/names.html">names</a></span><span class="op">(</span><span class="va">.x</span><span class="op">$</span><span class="va">betas</span><span class="op">)</span>, collapse <span class="op">=</span> <span class="st">", "</span><span class="op">)</span>
  <span class="op">)</span>
<span class="op">)</span>
<span class="co">#&gt; # A tibble: 4 × 6</span>
<span class="co">#&gt;       p   rsq rsqadj    cp   mse terms                   </span>
<span class="co">#&gt;   &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;                   </span>
<span class="co">#&gt; 1     1 0      0      31.3 30.7  (Intercept)             </span>
<span class="co">#&gt; 2     2 0.432  0.361  16.3 19.6  (Intercept), age        </span>
<span class="co">#&gt; 3     2 0.246  0.152  23.6 26.0  (Intercept), height     </span>
<span class="co">#&gt; 4     3 0.822  0.771   3    7.04 (Intercept), age, height</span></code></pre></div>
<p>위 과정은 함수 <code><a href="../reference/evaluate_linear_regression.html">evaluate_linear_regression()</a></code>에 구현되어 있다.</p>
<div class="sourceCode" id="cb29"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="../reference/evaluate_linear_regression.html">evaluate_linear_regression</a></span><span class="op">(</span><span class="va">biometric</span>, <span class="va">weight</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">age</span>, <span class="va">height</span><span class="op">)</span><span class="op">)</span>
<span class="co">#&gt; # A tibble: 4 × 6</span>
<span class="co">#&gt;       p   rsq rsqadj    cp   mse terms                   </span>
<span class="co">#&gt;   &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;                   </span>
<span class="co">#&gt; 1     1 0      0      31.3 30.7  (Intercept)             </span>
<span class="co">#&gt; 2     2 0.432  0.361  16.3 19.6  (Intercept), age        </span>
<span class="co">#&gt; 3     2 0.246  0.152  23.6 26.0  (Intercept), height     </span>
<span class="co">#&gt; 4     3 0.822  0.771   3    7.04 (Intercept), age, height</span></code></pre></div>
</div>
<div id="단계적-변수선택" class="section level2" number="5.3">
<h2 class="hasAnchor">
<a href="#%EB%8B%A8%EA%B3%84%EC%A0%81-%EB%B3%80%EC%88%98%EC%84%A0%ED%83%9D" class="anchor"></a><span class="header-section-number">5.3</span> 단계적 변수선택</h2>
<p>완전모형에 포함되는 <span class="math inline">\(k\)</span>개의 변수 중에서 적절한 독립변수를 단계적으로 선택하는 방법 중 단계별방법(stepwise method)에 대해 알아보자. 이 방법은 <span class="math inline">\(k\)</span>개의 독립변수 후보들 중에서 종속변수에 가장 큰 영향을 주는 변수들부터 선택하며 모형에 포함시키면서, 새롭게 모형에 추가된 변수에 기인하여 기존 변수가 그 중요도가 약화되어 모형으로부터 제거될 수 있는지를 매 단계별로 검토하여 해당 변수를 제거하는 과정을 거치며, 추가 또는 제거되는 변수가 더 이상 없을 때 변수 선택을 완료하는 방법이다. 이 때, 각 변수의 추가/제거 단계에서 개별 기울기 회귀계수에 대한 <span class="math inline">\(F\)</span>-검정을 적용한다. 이 때, 각 변수를 추가할 때 적용하는 유의수준 <span class="math inline">\(\alpha_{in}\)</span>은 제거할 때 적용하는 유의수준 <span class="math inline">\(\alpha_{out}\)</span>보다 작거나 같게 설정한다. 즉, 변수가 포함되는 것을 변수가 제거되는 것보다 어렵게 한다.</p>
<p>각각의 변수 추가/제거 단계에서 적용되는 <span class="math inline">\(F\)</span> 값(<span class="math inline">\(\alpha_{in}\)</span>과 <span class="math inline">\(\alpha_{out}\)</span>에 대응하는 값)들을 각각 <span class="math inline">\(F_{in}\)</span>, <span class="math inline">\(F_{out}\)</span>이라 하자.</p>
<div class="sourceCode" id="cb30"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">alpha_in</span> <span class="op">&lt;-</span> <span class="fl">0.05</span>
<span class="va">alpha_out</span> <span class="op">&lt;-</span> <span class="fl">0.10</span>
<span class="va">variables</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"age"</span>, <span class="st">"height"</span><span class="op">)</span></code></pre></div>
<ul>
<li>
<strong>[단계 1]</strong> <span class="math inline">\(k\)</span>개의 변수 각각을 이용하여 <span class="math inline">\(k\)</span>개의 회귀모형을 구하고, <span class="math inline">\(SSR\)</span>이 가장 큰 모형에 해당하는 변수(<span class="math inline">\(x_{(1)}\)</span>이라 하자)를 선택한다. 해당 모형에서 변수에 대한 <span class="math inline">\(F\)</span>값이 <span class="math inline">\(F_{in}\)</span>보다 크면 변수 <span class="math inline">\(x_{(1)}\)</span>을 모형에 포함시킨다. 그렇지 않으면, 아무 변수도 모형에 포함시키지 않은 채 변수 선택을 종료한다.</li>
</ul>
<div class="sourceCode" id="cb31"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">variables_in_model</span> <span class="op">&lt;-</span> <span class="fu">purrr</span><span class="fu">::</span><span class="fu"><a href="https://purrr.tidyverse.org/reference/map.html">map_dfr</a></span><span class="op">(</span>
  <span class="va">variables</span>,
  <span class="op">~</span> <span class="fu"><a href="../reference/test_type2_linear_regression.html">test_type2_linear_regression</a></span><span class="op">(</span><span class="va">biometric</span>, <span class="va">weight</span>, <span class="va">.x</span><span class="op">)</span>
<span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu">dplyr</span><span class="fu">::</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/slice.html">slice_max</a></span><span class="op">(</span><span class="va">ss</span>, n <span class="op">=</span> <span class="fl">1L</span>, with_ties <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu">dplyr</span><span class="fu">::</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/filter.html">filter</a></span><span class="op">(</span><span class="va">p_value</span> <span class="op">&lt;</span> <span class="va">alpha_in</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/pull.html">pull</a></span><span class="op">(</span><span class="va">terms</span><span class="op">)</span>

<span class="va">variables_in_model</span>
<span class="co">#&gt; [1] "age"</span></code></pre></div>
<ul>
<li>
<strong>[단계 2]</strong> 아직 모형에 포함되지 않은 변수 각각에 대해, 변수를 모형에 추가할 때 해당 변수에 대한 Type <span class="math inline">\(\text{II}\)</span> 제곱합을 산출한다. 최대 제곱합을 갖는 변수(<span class="math inline">\(x_j\)</span>라 하자)를 선택하고, 그 변수에 해당하는 <span class="math inline">\(F\)</span> 값을 산출한다. <span class="math inline">\(F\)</span> 값이 <span class="math inline">\(F_{in}\)</span>보다 크면 변수 <span class="math inline">\(x_j\)</span>를 모형에 포함시킨다. 그렇지 않으면, 변수 선택을 종료한다.</li>
</ul>
<div class="sourceCode" id="cb32"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">variables_not_in_model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://generics.r-lib.org/reference/setops.html">setdiff</a></span><span class="op">(</span><span class="va">variables</span>, <span class="va">variables_in_model</span><span class="op">)</span>

<span class="va">new_variable_in</span> <span class="op">&lt;-</span> <span class="fu">purrr</span><span class="fu">::</span><span class="fu"><a href="https://purrr.tidyverse.org/reference/map.html">map_dfr</a></span><span class="op">(</span>
  <span class="va">variables_not_in_model</span>,
  <span class="op">~</span> <span class="fu"><a href="../reference/test_type2_linear_regression.html">test_type2_linear_regression</a></span><span class="op">(</span><span class="va">biometric</span>, <span class="va">weight</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">variables_in_model</span>, <span class="va">.x</span><span class="op">)</span>, 
                                 .last_only <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>
<span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu">dplyr</span><span class="fu">::</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/slice.html">slice_max</a></span><span class="op">(</span><span class="va">ss</span>, n <span class="op">=</span> <span class="fl">1L</span>, with_ties <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu">dplyr</span><span class="fu">::</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/filter.html">filter</a></span><span class="op">(</span><span class="va">p_value</span> <span class="op">&lt;</span> <span class="va">alpha_in</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/pull.html">pull</a></span><span class="op">(</span><span class="va">terms</span><span class="op">)</span>
<span class="co">#&gt; Note: Using an external vector in selections is ambiguous.</span>
<span class="co">#&gt; ℹ Use `all_of(variables_in_model)` instead of `variables_in_model` to silence this message.</span>
<span class="co">#&gt; ℹ See &lt;https://tidyselect.r-lib.org/reference/faq-external-vector.html&gt;.</span>
<span class="co">#&gt; This message is displayed once per session.</span>
<span class="kw">if</span> <span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">new_variable_in</span><span class="op">)</span> <span class="op">==</span> <span class="fl">0L</span><span class="op">)</span> <span class="op">{</span>
  <span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="st">"변수 선택 종료"</span><span class="op">)</span>
<span class="op">}</span> <span class="kw">else</span> <span class="op">{</span>
  <span class="va">variables_in_model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">variables_in_model</span>, <span class="va">new_variable_in</span><span class="op">)</span>
  <span class="va">variables_not_in_model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://generics.r-lib.org/reference/setops.html">setdiff</a></span><span class="op">(</span><span class="va">variables_not_in_model</span>, <span class="va">new_variable_in</span><span class="op">)</span>
<span class="op">}</span></code></pre></div>
<ul>
<li>
<strong>[단계 3]</strong> 모형에 포함된 변수 각각에 대해 Type <span class="math inline">\(\text{II}\)</span> 제곱합을 산출한다. 최소 제곱합을 갖는 변수(<span class="math inline">\(x_i\)</span>라 하자)를 선택하고, 그 변수에 해당하는 <span class="math inline">\(F\)</span> 값을 산출한다. <span class="math inline">\(F\)</span> 값이 <span class="math inline">\(F_{out}\)</span>보다 작으면 변수 <span class="math inline">\(x_i\)</span>를 모형에서 제거하고, 그렇지 않으면 그대로 둔다. <strong>[단계 3]</strong>의 결과 모든 변수가 모형에 포함되어 있으면 변수 선택을 종료하고, 모형에 포함되지 않은 변수가 남아있는 경우 <strong>[단계 2]</strong>로 간다.</li>
</ul>
<div class="sourceCode" id="cb33"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">new_variable_out</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/test_type2_linear_regression.html">test_type2_linear_regression</a></span><span class="op">(</span><span class="va">biometric</span>, <span class="va">weight</span>, <span class="va">variables_in_model</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu">dplyr</span><span class="fu">::</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/slice.html">slice_min</a></span><span class="op">(</span><span class="va">ss</span>, n <span class="op">=</span> <span class="fl">1L</span>, with_ties <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu">dplyr</span><span class="fu">::</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/filter.html">filter</a></span><span class="op">(</span><span class="va">p_value</span> <span class="op">&gt;</span> <span class="va">alpha_out</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/pull.html">pull</a></span><span class="op">(</span><span class="va">terms</span><span class="op">)</span>

<span class="kw">if</span> <span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">new_variable_out</span><span class="op">)</span> <span class="op">&gt;</span> <span class="fl">0L</span><span class="op">)</span> <span class="op">{</span>
  <span class="va">variables_in_model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://generics.r-lib.org/reference/setops.html">setdiff</a></span><span class="op">(</span><span class="va">variables_in_model</span>, <span class="va">new_variable_out</span><span class="op">)</span>
  <span class="va">variables_not_in_model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">variables_not_in_model</span>, <span class="va">new_variable_out</span><span class="op">)</span>
<span class="op">}</span>

<span class="kw">if</span> <span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">variables_not_in_model</span><span class="op">)</span> <span class="op">==</span> <span class="fl">0L</span><span class="op">)</span> <span class="op">{</span>
  <span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="st">"변수 선택 종료"</span><span class="op">)</span>
<span class="op">}</span>
<span class="co">#&gt; [1] "변수 선택 종료"</span>
<span class="va">variables_in_model</span>
<span class="co">#&gt; [1] "age"    "height"</span></code></pre></div>
<p>위 단계적 변수 선택 방법을 함수 <code><a href="../reference/select_variables_stepwise.html">select_variables_stepwise()</a></code>로 수행할 수 있다.</p>
<div class="sourceCode" id="cb34"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">variables_selected</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/select_variables_stepwise.html">select_variables_stepwise</a></span><span class="op">(</span><span class="va">biometric</span>, <span class="va">weight</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">age</span>, <span class="va">height</span><span class="op">)</span><span class="op">)</span>
<span class="co">#&gt; Inital variable:  age , p-value =  0.03902789  &lt;  0.05 </span>
<span class="co">#&gt; Iteration  1 : forward selection - height , p-value =  0.00579269  &lt;  0.05 </span>
<span class="co">#&gt; Iteration  1 : backward elimination - no variable can be deleted without a statistically significant loss of fit.</span>
<span class="co">#&gt; Every variable provides statistically significant improvement of fit.</span>
<span class="va">variables_selected</span>
<span class="co">#&gt; [1] "age"    "height"</span></code></pre></div>
<p>위 예제 데이터에 대하여는 모든 변수가 선택된다.</p>
<p>다른 예로, 아래 세 개의 독립변수와 하나의 종속변수로 이루어진 데이터 프레임 <code>pcrdata</code>에 대해 단계별 변수 선택방법에 의해 회귀모형에 사용할 독립변수를 찾아보자.</p>
<div class="sourceCode" id="cb35"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">pcrdata</span>, package <span class="op">=</span> <span class="st">"dmtr"</span><span class="op">)</span>
<span class="va">pcrdata</span>
<span class="co">#&gt; # A tibble: 6 × 4</span>
<span class="co">#&gt;      x1    x2    x3     y</span>
<span class="co">#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;</span>
<span class="co">#&gt; 1    -3    -3     5   -30</span>
<span class="co">#&gt; 2    -2    -3     7   -20</span>
<span class="co">#&gt; 3     0     0     4     0</span>
<span class="co">#&gt; 4     1     2     0     5</span>
<span class="co">#&gt; 5     2     2    -5    10</span>
<span class="co">#&gt; 6     2     2   -11    35</span></code></pre></div>
<div class="sourceCode" id="cb36"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">pcrdata_variable_selected</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/select_variables_stepwise.html">select_variables_stepwise</a></span><span class="op">(</span><span class="va">pcrdata</span>, <span class="va">y</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">x1</span>, <span class="va">x2</span>, <span class="va">x3</span><span class="op">)</span><span class="op">)</span>
<span class="co">#&gt; Inital variable:  x1 , p-value =  0.00680743  &lt;  0.05 </span>
<span class="co">#&gt; Iteration  1 : forward selection - no additional variable gives statistically significant improvement of the fit.</span>
<span class="va">pcrdata_variable_selected</span>
<span class="co">#&gt; [1] "x1"</span></code></pre></div>
</div>
</div>
<div id="회귀모형의-진단" class="section level1" number="6">
<h1 class="hasAnchor">
<a href="#%ED%9A%8C%EA%B7%80%EB%AA%A8%ED%98%95%EC%9D%98-%EC%A7%84%EB%8B%A8" class="anchor"></a><span class="header-section-number">6</span> 회귀모형의 진단</h1>
<div id="잔차산점도" class="section level2" number="6.1">
<h2 class="hasAnchor">
<a href="#%EC%9E%94%EC%B0%A8%EC%82%B0%EC%A0%90%EB%8F%84" class="anchor"></a><span class="header-section-number">6.1</span> 잔차산점도</h2>
</div>
<div id="정규확률분포도" class="section level2" number="6.2">
<h2 class="hasAnchor">
<a href="#%EC%A0%95%EA%B7%9C%ED%99%95%EB%A5%A0%EB%B6%84%ED%8F%AC%EB%8F%84" class="anchor"></a><span class="header-section-number">6.2</span> 정규확률분포도</h2>
</div>
</div>
<div id="반응치에-대한-추정-및-예측" class="section level1" number="7">
<h1 class="hasAnchor">
<a href="#%EB%B0%98%EC%9D%91%EC%B9%98%EC%97%90-%EB%8C%80%ED%95%9C-%EC%B6%94%EC%A0%95-%EB%B0%8F-%EC%98%88%EC%B8%A1" class="anchor"></a><span class="header-section-number">7</span> 반응치에 대한 추정 및 예측</h1>
<p>회귀모형이 추정된 후 독립변수의 새로운 관측치에 대하여 종속변수값을 예측한다. 독립변수의 새로운 관측치 <span class="math inline">\(\mathbf{x}_{new} = c(1, x_{new, 1}, x_{new, 2}, \cdots, x_{new, k})\)</span>에 대응하는 종속변수값은 확률변수라 할 수 있는데, 이를 미래반응치(future response) <span class="math inline">\(y_{new}\)</span>라 한다. 동일한 독립변수 관측치 <span class="math inline">\(\mathbf{x}_{new}\)</span> 수준에서 종속변수값을 여러 번 측정할 때 평균적으로 취하는 값(기대치)를 평균반응치(mean response) <span class="math inline">\(E[y_{new} \, | \, \mathbf{x}_{new}]\)</span>라 한다.</p>
<p>위 나이/키/몸무게 데이터로 이루어진 회귀모형 예제에서, 나이가 40세이고 키가 170cm이며, 몸무게는 측정이 되지 않은 새로운 관측치가 있다고 하자.</p>
<div class="sourceCode" id="cb37"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">x_new</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span>`(Intercept)` <span class="op">=</span> <span class="fl">1</span>, age <span class="op">=</span> <span class="fl">40</span>, height <span class="op">=</span> <span class="fl">170</span><span class="op">)</span></code></pre></div>
<div id="평균반응치의-추정" class="section level2" number="7.1">
<h2 class="hasAnchor">
<a href="#%ED%8F%89%EA%B7%A0%EB%B0%98%EC%9D%91%EC%B9%98%EC%9D%98-%EC%B6%94%EC%A0%95" class="anchor"></a><span class="header-section-number">7.1</span> 평균반응치의 추정</h2>
<p>평균반응치는 아래와 같다.</p>
<p><span class="math display">\[
E\left[y_{new} \, | \, \mathbf{x}_{new}\right] = \mathbf{x}_{new}^{\top} \boldsymbol{\beta}
\]</span></p>
<p>이 때, 평균반응치의 추정량은 위에서 추정한 회귀모형을 이용하여 다음과 같이 구할 수 있다.</p>
<p><span class="math display">\[
\hat{y}_{new} = \mathbf{x}_{new}^{\top} \hat{\boldsymbol{\beta}}
\]</span></p>
<div class="sourceCode" id="cb38"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">y_new_hat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">x_new</span> <span class="op">*</span> <span class="va">fit</span><span class="op">$</span><span class="va">betas</span><span class="op">)</span>
<span class="va">y_new_hat</span>
<span class="co">#&gt; [1] 67.39739</span></code></pre></div>
<p>평균반응치에 대한 신뢰구간을 구하기 위해 우선 <span class="math inline">\(\hat{y}_{new}\)</span>의 분산을 아래와 같이 구한다.</p>
<p><span class="math display">\[
Var(\hat{y}_{new}) = \mathbf{x}_{new}^{\top} Var(\hat{\beta}) \mathbf{x}_{new} = \sigma^2 \mathbf{x}_{new}^{\top} (\mathbf{X}^{\top} \mathbf{X})^{-1} \mathbf{x}_{new}
\]</span></p>
<p>위 식에 <span class="math inline">\(\sigma^2\)</span> 대신 <span class="math inline">\(MSE\)</span>를 대입하여 <span class="math inline">\(\hat{y}_{new}\)</span>의 분산을 추정한다.</p>
<p><span class="math display">\[
\widehat{Var}(\hat{y}_{new}) = MSE \, \mathbf{x}_{new}^{\top} (\mathbf{X}^{\top} \mathbf{X})^{-1} \mathbf{x}_{new}
\]</span></p>
<p>위 분산 추정치에 제곱근을 취하면 <span class="math inline">\(\hat{y}_{new}\)</span>의 표준오차를 구할 수 있다.</p>
<p><span class="math display">\[
se(\hat{y}_{new}) = \sqrt{MSE \, \mathbf{x}_{new}^{\top} (\mathbf{X}^{\top} \mathbf{X})^{-1} \mathbf{x}_{new}}
\]</span></p>
<div class="sourceCode" id="cb39"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">y_new_se</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="va">fit</span><span class="op">$</span><span class="va">mse</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/t.html">t</a></span><span class="op">(</span><span class="va">x_new</span><span class="op">)</span> <span class="op">%*%</span> <span class="fu"><a href="https://rdrr.io/r/base/solve.html">solve</a></span><span class="op">(</span><span class="va">fit</span><span class="op">$</span><span class="va">hessian</span> <span class="op">/</span> <span class="fl">2</span><span class="op">)</span> <span class="op">%*%</span> <span class="va">x_new</span><span class="op">)</span> <span class="op">%&gt;%</span> <span class="fu"><a href="https://rdrr.io/r/base/drop.html">drop</a></span><span class="op">(</span><span class="op">)</span>
<span class="va">y_new_se</span>
<span class="co">#&gt; [1] 1.006575</span></code></pre></div>
<p>이 때, 평균반응치 <span class="math inline">\(E\left[y_{new} \, | \, \mathbf{x}_{new}\right]\)</span>의 <span class="math inline">\(100(1 - \alpha)\%\)</span> 신뢰구간은 다음과 같이 산출된다.</p>
<p><span class="math display">\[
\hat{y}_{new} \pm t_{(\alpha/2, \, n - k - 1)} se(\hat{y}_{new})
\]</span></p>
<div class="sourceCode" id="cb40"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">alpha</span> <span class="op">&lt;-</span> <span class="fl">0.05</span>
<span class="va">y_new_confint</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span>
  <span class="va">y_new_hat</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/TDist.html">qt</a></span><span class="op">(</span><span class="va">alpha</span> <span class="op">/</span> <span class="fl">2</span>, df <span class="op">=</span> <span class="va">fit</span><span class="op">$</span><span class="va">df</span><span class="op">)</span> <span class="op">*</span> <span class="va">y_new_se</span>,
  <span class="va">y_new_hat</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/TDist.html">qt</a></span><span class="op">(</span><span class="va">alpha</span> <span class="op">/</span> <span class="fl">2</span>, df <span class="op">=</span> <span class="va">fit</span><span class="op">$</span><span class="va">df</span>, lower.tail <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span> <span class="op">*</span> <span class="va">y_new_se</span>
<span class="op">)</span>
<span class="va">y_new_confint</span>
<span class="co">#&gt; [1] 65.01722 69.77757</span></code></pre></div>
<p>위 과정을 함수 <code><a href="../reference/predict_linear_regression.html">predict_linear_regression()</a></code>으로 수행할 수 있다. 이 때, <code>.ci_interval</code>은 <span class="math inline">\((1 - \alpha)\)</span>값을 나타낸다.</p>
<div class="sourceCode" id="cb41"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="../reference/predict_linear_regression.html">predict_linear_regression</a></span><span class="op">(</span>
  <span class="va">fit</span>,
  .new_data <span class="op">=</span> <span class="fu"><a href="https://tibble.tidyverse.org/reference/tibble.html">tibble</a></span><span class="op">(</span>age <span class="op">=</span> <span class="fl">40</span>, height <span class="op">=</span> <span class="fl">170</span><span class="op">)</span>,
  .xvar <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">age</span>, <span class="va">height</span><span class="op">)</span>,
  .ci_interval <span class="op">=</span> <span class="fl">0.95</span>
<span class="op">)</span>
<span class="co">#&gt; # A tibble: 1 × 4</span>
<span class="co">#&gt;   .pred   .se .ci_lower .ci_upper</span>
<span class="co">#&gt;   &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;</span>
<span class="co">#&gt; 1  67.4  1.01      65.0      69.8</span></code></pre></div>
</div>
<div id="미래반응치의-추정" class="section level2" number="7.2">
<h2 class="hasAnchor">
<a href="#%EB%AF%B8%EB%9E%98%EB%B0%98%EC%9D%91%EC%B9%98%EC%9D%98-%EC%B6%94%EC%A0%95" class="anchor"></a><span class="header-section-number">7.2</span> 미래반응치의 추정</h2>
<p>미래반응치 <span class="math inline">\(y_{new}\)</span>의 예측치는 평균반응치의 추정치 <span class="math inline">\(\hat{y}_{new}\)</span>와 동일하다.</p>
<p>미래반응치의 예측구간을 구하기 위해서는 예측오차의 분산을 알아야 하며, 이는 아래와 같이 수식으로 표현된다.</p>
<p><span class="math display">\[
Var(y_{new} - \hat{y}_{new}) = \sigma^2 + \sigma^2 \mathbf{x}_{new}^{\top} (\mathbf{X}^{\top} \mathbf{X})^{-1} \mathbf{x}_{new}
\]</span></p>
<p>즉, 예측오차의 분산은 회귀모형의 오차항의 분산 <span class="math inline">\(\sigma^2\)</span>과 평균반응치 추정치의 분산 <span class="math inline">\(\sigma^2 \mathbf{x}_{new}^{\top} (\mathbf{X}^{\top} \mathbf{X})^{-1} \mathbf{x}_{new}\)</span>의 합이다.</p>
<p>이 때, 미래반응치 <span class="math inline">\(y_{new}\)</span>의 <span class="math inline">\(100(1 - \alpha)\%\)</span> 예측구간은 다음과 같이 산출된다.</p>
<p><span class="math display">\[
\hat{y}_{new} \pm t_{(\alpha/2, \, n - k - 1)} \sqrt{MSE + se^2(\hat{y}_{new})}
\]</span></p>
<div class="sourceCode" id="cb42"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">alpha</span> <span class="op">&lt;-</span> <span class="fl">0.05</span>
<span class="va">y_new_predint</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span>
  <span class="va">y_new_hat</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/TDist.html">qt</a></span><span class="op">(</span><span class="va">alpha</span> <span class="op">/</span> <span class="fl">2</span>, df <span class="op">=</span> <span class="va">fit</span><span class="op">$</span><span class="va">df</span><span class="op">)</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="va">fit</span><span class="op">$</span><span class="va">mse</span> <span class="op">+</span> <span class="va">y_new_se</span> <span class="op">^</span> <span class="fl">2</span><span class="op">)</span>,
  <span class="va">y_new_hat</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/TDist.html">qt</a></span><span class="op">(</span><span class="va">alpha</span> <span class="op">/</span> <span class="fl">2</span>, df <span class="op">=</span> <span class="va">fit</span><span class="op">$</span><span class="va">df</span>, lower.tail <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="va">fit</span><span class="op">$</span><span class="va">mse</span> <span class="op">+</span> <span class="va">y_new_se</span> <span class="op">^</span> <span class="fl">2</span><span class="op">)</span>
<span class="op">)</span>
<span class="va">y_new_predint</span>
<span class="co">#&gt; [1] 60.68767 74.10712</span></code></pre></div>
<p>위 과정을 함수 <code><a href="../reference/predict_linear_regression.html">predict_linear_regression()</a></code>으로 수행할 수 있다. 이 때, <code>.pi_interval</code>은 <span class="math inline">\((1 - \alpha)\)</span>값을 나타낸다.</p>
<div class="sourceCode" id="cb43"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="../reference/predict_linear_regression.html">predict_linear_regression</a></span><span class="op">(</span>
  <span class="va">fit</span>,
  .new_data <span class="op">=</span> <span class="fu"><a href="https://tibble.tidyverse.org/reference/tibble.html">tibble</a></span><span class="op">(</span>age <span class="op">=</span> <span class="fl">40</span>, height <span class="op">=</span> <span class="fl">170</span><span class="op">)</span>,
  .xvar <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">age</span>, <span class="va">height</span><span class="op">)</span>,
  .pi_interval <span class="op">=</span> <span class="fl">0.95</span>
<span class="op">)</span>
<span class="co">#&gt; # A tibble: 1 × 4</span>
<span class="co">#&gt;   .pred   .se .pi_lower .pi_upper</span>
<span class="co">#&gt;   &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;</span>
<span class="co">#&gt; 1  67.4  1.01      60.7      74.1</span></code></pre></div>
</div>
<div id="예측성능-평가" class="section level2" number="7.3">
<h2 class="hasAnchor">
<a href="#%EC%98%88%EC%B8%A1%EC%84%B1%EB%8A%A5-%ED%8F%89%EA%B0%80" class="anchor"></a><span class="header-section-number">7.3</span> 예측성능 평가</h2>
<p>회귀분석을 예측의 목적으로 사용하는 경우, 예측성능을 평가하는 것이 중요하다. 이를 위해서 학습표본을 훈련표본(training sample)과 테스트 표본(test sample)의 두 부분으로 나누고, 훈련표본만을 사용하여 회귀모형을 구축한 후, 테스트 표본의 독립변수를 사용하여 종속변수를 예측하고, 실제 종속변수값과 비교하여 예측성능을 평가하는 것이다.</p>
<p>예측오차의 척도로 여러 가지를 사용할 수 있으나, 평균절대오차(mean absolute deviation; MAD), 평균제곱오차(mean squared error; MSE) 또는 평균제곱오차의 제곱근(root mean squared error; RMS)을 널리 사용한다.</p>
<p>위에서 회귀모형 추정에 사용한 관측치들 외에 아래와 같이 실제 종속변수값이 관측된 세 개의 테스트 표본이 존재한다고 하자.</p>
<div class="sourceCode" id="cb44"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">test_sample</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://tibble.tidyverse.org/reference/tribble.html">tribble</a></span><span class="op">(</span>
  <span class="op">~</span><span class="va">age</span>, <span class="op">~</span><span class="va">height</span>, <span class="op">~</span><span class="va">weight</span>,
  <span class="fl">30</span>, <span class="fl">175</span>, <span class="fl">75</span>,
  <span class="fl">40</span>, <span class="fl">170</span>, <span class="fl">68</span>,
  <span class="fl">50</span>, <span class="fl">165</span>, <span class="fl">60</span>
<span class="op">)</span></code></pre></div>
<p>우선, 추정된 회귀모형을 이용하여 각 테스트 표본에 대한 예측값을 구하고, 실제 관측값과의 차이를 계산한다.</p>
<div class="sourceCode" id="cb45"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">test_prediction_error</span> <span class="op">&lt;-</span> <span class="va">test_sample</span><span class="op">[[</span><span class="st">"weight"</span><span class="op">]</span><span class="op">]</span> <span class="op">-</span> 
  <span class="op">(</span><span class="fu"><a href="../reference/predict_linear_regression.html">predict_linear_regression</a></span><span class="op">(</span><span class="va">fit</span>, <span class="va">test_sample</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">age</span>, <span class="va">height</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/pull.html">pull</a></span><span class="op">(</span><span class="va">.pred</span><span class="op">)</span><span class="op">)</span>
<span class="va">test_prediction_error</span>
<span class="co">#&gt; [1]  6.1183987  0.6026067 -5.9131854</span></code></pre></div>
<p>이 때, 평균절대오차, 평균제곱오차 및 그 제곱근은 아래와 같이 계산된다.</p>
<div class="sourceCode" id="cb46"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://tibble.tidyverse.org/reference/tibble.html">tibble</a></span><span class="op">(</span>
  mad <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">abs</a></span><span class="op">(</span><span class="va">test_prediction_error</span><span class="op">)</span><span class="op">)</span>,
  mse <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">test_prediction_error</span> <span class="op">^</span> <span class="fl">2</span><span class="op">)</span>,
  rmse <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">test_prediction_error</span> <span class="op">^</span> <span class="fl">2</span><span class="op">)</span><span class="op">)</span>
<span class="op">)</span>
<span class="co">#&gt; # A tibble: 1 × 3</span>
<span class="co">#&gt;     mad   mse  rmse</span>
<span class="co">#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;</span>
<span class="co">#&gt; 1  4.21  24.3  4.92</span></code></pre></div>
<p>위 각각의 평가척도는 함수 <code><a href="../reference/eval_mad.html">eval_mad()</a></code>, <code><a href="../reference/eval_mse.html">eval_mse()</a></code>, 그리고 <code><a href="../reference/eval_rmse.html">eval_rmse()</a></code>로 확인할 수 있다. 각 함수들은 관측치 벡터 <code>.y</code>와 예측치 벡터 <code>.y_hat</code>을 입력값으로 사용한다.</p>
<div class="sourceCode" id="cb47"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>
  mad <span class="op">=</span> <span class="va">eval_mad</span>,
  mse <span class="op">=</span> <span class="va">eval_mse</span>,
  rmse <span class="op">=</span> <span class="va">eval_rmse</span>
<span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu">purrr</span><span class="fu">::</span><span class="fu"><a href="https://purrr.tidyverse.org/reference/map.html">map_dbl</a></span><span class="op">(</span>
    <span class="fu">rlang</span><span class="fu">::</span><span class="va"><a href="https://rlang.r-lib.org/reference/invoke.html">invoke</a></span>,
    .args <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>
      .y <span class="op">=</span> <span class="va">test_sample</span><span class="op">[[</span><span class="st">"weight"</span><span class="op">]</span><span class="op">]</span>,
      .y_hat <span class="op">=</span> <span class="fu"><a href="../reference/predict_linear_regression.html">predict_linear_regression</a></span><span class="op">(</span><span class="va">fit</span>, <span class="va">test_sample</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">age</span>, <span class="va">height</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/pull.html">pull</a></span><span class="op">(</span><span class="va">.pred</span><span class="op">)</span>    
    <span class="op">)</span>
  <span class="op">)</span>
<span class="co">#&gt;       mad       mse      rmse </span>
<span class="co">#&gt;  4.211397 24.254567  4.924893</span></code></pre></div>
</div>
</div>
<div id="다중공선성" class="section level1" number="8">
<h1 class="hasAnchor">
<a href="#%EB%8B%A4%EC%A4%91%EA%B3%B5%EC%84%A0%EC%84%B1" class="anchor"></a><span class="header-section-number">8</span> 다중공선성</h1>
<p>독립변수들 사이에 상당히 높은 선형관계가 존재하는 현상을 다중공선성(multicollinearity)이라고 한다. 완전공선성(perfect collinearity)이 존재하는 경우에는 <span class="math inline">\(\mathbf{X}^{\top} \mathbf{X}\)</span>의 역행렬이 존재하지 않아 회귀계수를 추정할 수 없게 된다. 완전공선성은 없다 하여도 다중공선성이 경우에는 추정된 회귀계수의 분산이 매우 커지며, 따라서 정확한 모수추정 및 검정에 어려움이 있다.</p>
<div id="다중공선성-척도---분산팽창계수variance-inflation-factor-vif" class="section level2" number="8.1">
<h2 class="hasAnchor">
<a href="#%EB%8B%A4%EC%A4%91%EA%B3%B5%EC%84%A0%EC%84%B1-%EC%B2%99%EB%8F%84---%EB%B6%84%EC%82%B0%ED%8C%BD%EC%B0%BD%EA%B3%84%EC%88%98variance-inflation-factor-vif" class="anchor"></a><span class="header-section-number">8.1</span> 다중공선성 척도 - 분산팽창계수(variance inflation factor; <span class="math inline">\(VIF\)</span>)</h2>
<p><span class="math inline">\(j\)</span>번째 회귀계수의 추정량 <span class="math inline">\(\hat{\beta}_j\)</span>에 대한 분산팽창계수 <span class="math inline">\(VIF_j\)</span>는 다음과 같이 정의된다.</p>
<p><span class="math display">\[
VIF_j = \frac{1}{1 - R_j^2}
\]</span></p>
<p>여기서 <span class="math inline">\(R_j\)</span>는 <span class="math inline">\(j\)</span>번째 변수를 독립변수로 하고 나머지 <span class="math inline">\(1, \ldots, j -1, j + 1, \ldots, k\)</span> 번째 변수들을 독립변수로 하는 회귀모형에서의 결정계수를 말한다.</p>
<p>각 독립변수에 대한 분산팽창계수를 계산은 함수 <code><a href="../reference/vif_linear_regression.html">vif_linear_regression()</a></code>으로 구현되어 있다.</p>
<div class="sourceCode" id="cb48"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="../reference/vif_linear_regression.html">vif_linear_regression</a></span><span class="op">(</span><span class="va">biometric</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">age</span>, <span class="va">height</span><span class="op">)</span><span class="op">)</span>
<span class="co">#&gt; # A tibble: 2 × 2</span>
<span class="co">#&gt;   terms    vif</span>
<span class="co">#&gt;   &lt;chr&gt;  &lt;dbl&gt;</span>
<span class="co">#&gt; 1 age     1.03</span>
<span class="co">#&gt; 2 height  1.03</span></code></pre></div>
<p>일반적으로 <span class="math inline">\(k\)</span>개의 <span class="math inline">\(VIF_j\)</span> 중 가장 큰 값이 5를 넘으면(가장 큰 <span class="math inline">\(R_j^2\)</span>이 0.8을 넘으면) 다중공선성이 있다고 할 수 있으며, 10보다 큰 값이면 심각하다고 볼 수 있다.</p>
</div>
<div id="다중공선성-해결-방법" class="section level2" number="8.2">
<h2 class="hasAnchor">
<a href="#%EB%8B%A4%EC%A4%91%EA%B3%B5%EC%84%A0%EC%84%B1-%ED%95%B4%EA%B2%B0-%EB%B0%A9%EB%B2%95" class="anchor"></a><span class="header-section-number">8.2</span> 다중공선성 해결 방법</h2>
<p>다중공선성을 해결하기 위한 이론적 방법으로는 모수추정을 위해 최소자승법 대신에 주성분회귀(principal component regression), 부분최소자승 회귀(partial least squares regression)를 사용하는 방법이 있다. 이 방법들은 다른 장에서 별도로 다룬다.</p>
</div>
</div>
<div id="지시변수와-회귀모형" class="section level1" number="9">
<h1 class="hasAnchor">
<a href="#%EC%A7%80%EC%8B%9C%EB%B3%80%EC%88%98%EC%99%80-%ED%9A%8C%EA%B7%80%EB%AA%A8%ED%98%95" class="anchor"></a><span class="header-section-number">9</span> 지시변수와 회귀모형</h1>
<p>독립변수가 정량적 변수가 아니라 범주형 변수일 경우, 지시변수를 생성하여 모형을 추정한다. 범주의 수가 <span class="math inline">\(m\)</span>인 범주형 변수에 대해서 <span class="math inline">\(m - 1\)</span>개의 지시변수를 생성하여야 한다. 이 때, 모형의 분석에 있어서 정량적 변수로만 이루어진 모형과 다르게 고려해야 할 부분들이 있다. 예를 들어, 위에서 살펴본 분산팽창계수의 경우, 범주형 변수가 포함될 때의 분산팽창계수는 보다 일반화된 식을 필요로 한다.</p>
<p>본 패키지에서는 범주형 변수를 이용한 회귀모형은 고려하지 않기로 한다.</p>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

      </div>

</div>



      <footer><div class="copyright">
  <p>Developed by Youngrok Lee.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.6.1.</p>
</div>

      </footer>
</div>

  


  </body>
</html>
